# -*- mode: org; -*-

#+CATEGORY: STAGE

#+begin_src emacs-lisp :results none :export none
  (org-babel-tangle-file "README.org")
#+end_src

Le dossier contient les données du séquençage des deux plaques envoyées à la
suite des manips de Florence. 

* Analyse globale des SNP 

[2016-01-06 Wed] La première approche globale consiste à extraire les données
de séquence des fichiers .ab1 contenant les spectrogrammes et de les convertir
en fastq, de façon à conserver l'information de qualité du pic. Les séquences
sont ensuite trimmées, pour ne conserver que les positions dont la qualité est
suffisante. La qualité des séquences obtenues est contrôlée avant et après
trimming.

Les séquences fastq obtenues sont ensuite poolées dans un même fichier
~trimmed.fastq~, et alignées avec la séquence de référence. Les positions de SNP
sont inférées. Le tableau de donnée obtenu est analysée dans ~R~.
** Extraction des données brutes
Pour extraire les données du fichier brut .zip à la structure de données.

#+BEGIN_SRC sh :tangle ./scripts/extract_raw_data.sh 
  #!/bin/bash 

  cd ~/stage/seq_novembre/
  # Le script qui extrait les données depuis les fichiers zip bruts et qui met en
  # place la structure de fichier.

  cd ./data
  ## extraction des données brutes
  unzip raw_seq_nvbr/1369607.zip
  unzip raw_seq_nvbr/1369628.zip

  ## crée les dossiers
  mkdir fasta seq spectrograms csv
  ## déplace tout les fichiers dans des dossiers adaptés 
  find . -name "*.fas" -exec mv -i {} -t ./fasta/ \;
  find . -name "*.ab1" -exec mv -i {} -t ./spectrograms/ \;
  find . -name "*.seq" -exec mv -i {} -t ./seq/ \;
  find . -name "*.csv" -exec mv -i {} -t ./csv/ \;

  # déplace le contenu du dossier inutile dans le présent dossier
  mv 1369628/* ./
  rm -r 1369628 # supprime le dossier
  # déplace le fichier pdf dans le dossier adapté
  mv *.pdf ../analysis
#+END_SRC

Les spectrogrammes contiennent l'info de la sequence_id et du nom. 
On construit une table avec la qualité du mutant en troisième colonne. 

#+BEGIN_SRC python :tangle ./scripts/make_id_table.py
  from Bio import SeqIO
  import glob

  def strong_or_weak(record):
      """
      Determine si le mutant est strong ou weak
      """
      if 'S' in record:
          return 'strong'
      else:
          return 'weak'

  # en-tete de colonne
  print "id name mutant"

  # pour chaque fichier ab1
  for file in glob.glob("../data/spectrograms/*.ab1"):
      with open(file, "rb") as spectro:
          for record in SeqIO.parse(spectro, "abi"):
              # associer l'id avec le nom et le type de mutant
              print record.id + " " + record.name + \
                  " " + strong_or_weak(record.name)
#+END_SRC

On crée la table en question via :
#+BEGIN_SRC sh
  cd ~/stage/seq_novembre/scripts
  python make_id_table.py > ../data/id_table.dat
#+END_SRC

** Des spectrogrammes aux données fastq non-trimmées
*** prérequis

#+BEGIN_SRC sh
brew install emboss
#+END_SRC

*** via seqret

#+BEGIN_SRC sh :tangle ./scripts/ab1_to_fastq.sh
  cd ~/stage/seq_novembre/scripts

  touch untrimmed.fastq
  for file in ../data/spectrograms/*.ab1
  do
      seqret \
          -sformat abi \
          -osformat fastq \
          -auto \
          -stdout \
          -sequence $file \
          >> ../data/untrimmed.fastq
  done

  ## convertit le fastq en fasta
  seqret \
      -sformat fastq \
      -osformat fasta \
      -auto \
      -stdout \
      -sequence ../data/untrimmed.fastq \
      > ../data/untrimmed.fasta
#+END_SRC

** Des données non-trimmées aux données trimmées et filtrées
Un script qui convertit le fichier [[./data/untrimmed.fastq]] en fichier
[[./data/trimmed.fastq]]. /bbduk/ trimme les bases de faible qualité. /seqtk/
convertit les bases restantes de faible qualité en N, /seqret/ convertit le fastq
généré en fasta. 

#+BEGIN_SRC sh :tangle ./scripts/trim_low_quality.sh
  #!/usr/local/bin/bash

  #' -qtrim=rl : quality trim right and left 
  #' -trimq=28 : trim if quality < 28 (sanger encoding, illumina 1.9)
  #' -minlen=620 : keep only seq with length > 620, after trimming.
  #' -Xmx1g : tells bbduk / java to use 1G of RAM

  if [[ -f ../data/untrimmed.fastq && ! -f ../data/trim.fastq ]]
  then # si les fichiers n'existent pas.
      ~/.bin/bbmap/bbduk.sh -Xmx1g \
                            -in=../data/untrimmed.fastq \
                            -out=../data/trim.fastq \
                            -qtrim=rl \
                            -trimq=28 \
                            -minlen=620

      ## convertit les bases d'une qualité inférieure à 20 en N.
      seqtk seq -q20 -nN ../data/trim.fastq > ../data/trimmed.fastq

      ## convertit le fastq en fasta
      seqret -sformat fastq -osformat fasta -auto -stdout \
             -sequence ../data/trimmed.fastq > ../data/trimmed.fasta

      rm ../data/trim.fastq
  else
      printf "Le fichier untrimmed.fastq n'existe pas, ou le fichier trimmed.fastq existe déjà."
  fi
#+END_SRC

** Contrôle de la qualité des séquences
Le script utilisé pour analyser les données de qualité via /fastqc/. 

#+BEGIN_SRC sh :tangle scripts/quality_check.sh
  #!/usr/local/bin/bash
  cd ~/stage/seq_novembre/scripts

  # quand dans le dossier ./scripts
  cd ../data/

  if [ -f untrimmed.fastq ] && [ -f trimmed.fastq ] ; then
      mkdir tmp
      # analyse les données et output dans tmp
      fastqc untrimmed.fastq -o ./tmp
      fastqc trimmed.fastq   -o ./tmp
      # unzip resulting files
      unzip -qq tmp/untrimmed_fastqc.zip -d tmp
      unzip -qq tmp/trimmed_fastqc.zip -d tmp
      # extract main results
      mv tmp/untrimmed_fastqc/Images/per_base_quality.png \
         ../analysis/per_base_quality_fastqc_untrimmed.png
      mv tmp/trimmed_fastqc/Images/per_base_quality.png \
         ../analysis/per_base_quality_fastqc_trimmed.png
      # copy html into analysis
      mv tmp/*.html ../analysis/
      # delete tmp files
      rm -r tmp # remove temporary files

  else
      printf "Les fichiers untrimmed.fastq et trimmed.fastq n'existent pas."
  fi
#+END_SRC 

** Détermination des SNP

#+BEGIN_SRC sh :tangle ./scripts/variantCallerSsaha2.sh
  #!/bin/bash
  # variant calling using ssaha2 and ssaha2SNP

  cd ~/stage/seq_novembre/data
  ## prend le reverse complement de la séquence de référence
  fastx_reverse_complement -i reference.fasta -o reference_reverse.fasta

  mkdir variantCalling
  cd variantCalling

  ## place les séquences nécessaires pour l'analyse dans le dossier. 
  ln -s ../trimmed.fastq .
  ln -s ../reference_reverse.fasta ./reference_reverse.fasta

  ## alignement à la séquence de référence
  #' -output psl :             format de sortie psl
  #' reference_reverse.fasta : séquence de référence
  #' trimmed.fastq :           séquence à aligner
  #' output.psl :              fichier de sortie
  ~/.bin/ssahaSNP/ssaha2 -output psl reference_reverse.fasta trimmed.fastq > output.psl

  ## polymorphism detection tool
  ~/.bin/ssahaSNP/ssahaSNP reference_reverse.fasta trimmed.fastq > SNP.txt

  ## computer readable format conversion
  # egrep trouve les lignes où sont indiquées les données concernant les SNP
  # awk extrait les champs en question dans un fichier SNP.dat
  egrep ssaha:SNP SNP.txt | \
      awk '{print $1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14,$15}' > SNP.dat

  ## column annotation based on
  ## ftp://ftp.sanger.ac.uk/pub/resources/software/ssahasnp/readme,
  ## part (6) some further information
  # la première ligne du fichier .dat, afin d'être lu dans R
  echo " match subject_name index_of_subject read_name s_base q_base s_qual q_qual offset_on_subject offset_on_read length_of_snp start_match_of_read end_match_of_read match_direction length_of_subject " > head.dat
  # into final document
  cat head.dat SNP.dat > snp_calling.dat
#+END_SRC

** Analyse des variants
*** TODO Lecture des données et nettoyage
- [ ] nettoyer la partie "-1073" en trop dans les noms de séquence, et vérifier
  au long du code que ça ne pose pas de problème.

Le fichier [[~/stage/seq_novembre/data/variantCalling/snp_calling.dat]] contient les
données d'intérêt. Il ne contient ni le nom du transformant, ni son type (Weak
ou Strong). Les données sont récupérées dans le fichier [[./data/id_table.dat]]. Les
deux tables sont associés via un /inner-join/. 

On s'est rendu compte que le plasmide ~pS60~ était un contaminant, toutes les
mutations qu'il engendre sont de type /weak/. Il est donc rebasculé dans le
tableau des Weak. 

#+BEGIN_SRC R :tangle ./scripts/variant_analysis.R
  setwd("~/stage/seq_novembre/data/variantCalling")

  library(dplyr)

  ## read the data
  snp <- tbl_df(read.table("snp_calling.dat", head = TRUE))
  ## enlève les colonnes inutiles
  snp %>%
      select(
          -match, -subject_name, -index_of_subject, -length_of_subject,
          -match_direction, -contains("_of_read"), -contains("on_read"),
          -contains("_of_snp"), -s_qual
      ) -> snp
 
  ## lit les métadonnées de séquence
  id_table <- tbl_df(read.table("../id_table.dat", head = TRUE))

  ## fait correspondre le read_name avec le nom du clone et le type de mutant W ou S
  snp <- inner_join(x = snp, y = id_table, by = c("read_name" = "id"))

  ## suppress tmp var
  rm(id_table)

  ## bascule les contaminants mysterieux dans la bonne catégorie
  ## TESTE ET APPROUVE
  snp$mutant[snp$name == "pS60-1073"] <- "weak"
  snp$mutant[snp$name == "pS83-1073"] <- "weak"
  snp$mutant[snp$name == "pS92-1073"] <- "weak"
  snp$mutant[snp$name == "pS91-1073"] <- "weak"
  snp$mutant[snp$name == "pW6-1073" ] <- "strong"

#+END_SRC

*** Détermine la qualité des SNP
Pour déterminer si le SNP est de type /weak/ ou /strong/, j'utilise la fonction
=mutant_caller=. Si la référence est A ou T, soit le transformant est C ou G, et
la substitution est /WS/ ; soit le transformant est A ou T, et la mutation est
/WW/. Si la référence est C ou G, soit le transformant est A ou T, et la
substitution est /SW/ ; soit le transformant est G ou C, la substitution est
/SS/.

#+BEGIN_SRC R :tangle ./scripts/variant_analysis.R
  #' une fonction pour déterminer si la substitution est strong ou weak. On peut
  #' avoir des substitutions weak chez les strongs
  #' @param subject la base sur la séquence de référence
  #' @param query la base sur le read.
  mutant_caller <- function(subject, query)
  {
      if (subject == 'A' || subject == 'T') {
          if (query == 'C' || query == 'G' ) {
              'WS'
          } else {
              'WW'
          }
      } else if (subject == 'C' || subject == 'G') {
          if (query == 'A' || query == 'T') {
              'SW'
          } else {
              'SS'
          }
      }
  }

  ## on applique la fonction rowwise, ie ligne par ligne, via `mutate`, puis on
  ## dégroupe.
  snp %>%
      rowwise() %>%
      mutate(mutation_type = mutant_caller(s_base, q_base)) %>%
      ungroup() ->
      snp
  ## conversion en facteur
  snp$mutation_type = factor(snp$mutation_type)
#+END_SRC
*** Graphiques globaux
Des graphiques de distribution globale des SNP sont fait ici. 

#+BEGIN_SRC R :tangle ./scripts/variant_analysis.R
  ##==============================================================================
  ## SHORTCUT PLOT FUNCTION
  ##==============================================================================

  library(ggplot2)

  ##' .. content for \description{} (no empty lines) ..
  ##' 
  ##' Une fonction qui permet de court-circuiter ggplot : représente en ordonnée
  ##' la distribution des positions de snp, en abscisse la position des SNPs, par
  ##' défault la couleur repéresente le type de mutant, peut être également
  ##' attribuée à mutation_type. Respecte les critères visuels de tufte. Nécessite
  ##' ggplot2 1.02 si je ne m'abuse, avec l'option panel.ontop en tout cas.
  ##' 
  ##' .. content for \details{} ..
  ##' @title plot_snp
  ##' @param snp les données de snp
  ##' @param fill la couleur par laquelle on color les barres
  ##' @param legend_position la position de la légende sur le graphe
  ##' @param legend_name le titre de la légende. rien par défault
  ##' @return un graphique
  plot_snp <- function(data, fill_by = "mutant",
                                    legend_position = c(0.2, 0.8),
                                    legend_name = "")
  {
      plot <- ggplot(data = data, aes(offset_on_subject)) +
          theme_minimal(base_family = "Courier") +
          scale_x_continuous(breaks = seq(1, 734, 30)) +
          scale_fill_brewer(palette = "Set2", name = legend_name) +
          xlab("") +
          ylab("") +
          theme(panel.ontop = TRUE, legend.position = legend_position,
                axis.text = element_text(size = 8, colour = "gray"),
                panel.grid.major.x = element_blank(),
                panel.grid.minor.x = element_blank(),
                panel.grid.minor.y = element_blank(),
                panel.grid.major.y = element_line(colour = "white", size = 1))

      if (fill_by == "mutation_type")
      {
          plot + geom_histogram(aes(fill = mutation_type), binwidth = 10,
                                position = "dodge")
      } else {
          plot + geom_histogram(aes(fill = mutant), binwidth = 10,
                                position = "dodge")
      }
  }

  ##==============================================================================
  ## PLOT DISTRIBUTIONS
  ##==============================================================================

  pdf(file = "../../analysis/snp_distribution.pdf", height = 5.8, width = 8.3)

  ## distribution des SNP
  ## facétée par type de mutant, couleur = type de mutation
  snp %>%
      plot_snp(legend_name = "Exogene", legend_pos= c(.2, .8))

  dev.off()

  #-------------------------------------------------------------------------------
  pdf(file = "../../analysis/mutant_snp_distribution.pdf", height = 5.8, width = 8.3)

  snp %>%
      plot_snp(fill_by = "mutation_type", legend_name = "Type de Mutation" ) +
      facet_grid(mutant ~ .)

  dev.off()
#+END_SRC

*** Observations globales

Différents tableaux de résumé généraux. 

#+BEGIN_SRC R :tangle ./scripts/variant_analysis.R
  ## =============================================================================
  ## OBSERVATIONS GÉNÉRALES
  ## =============================================================================
 
  sink(file = "../../analysis/observations.tex")
  snp %>%
      group_by(mutant, name) %>%
      summarise(count = n()) %>%
      summarise(mean = mean(count), med = median(count), sd = sd(count) ) %>%
      knitr::kable( align = 'c', digits = 2, booktabs = TRUE, format = "latex")
  sink()

  sink(file = "../../analysis/count_by_mutant.tex")
  snp %>%
      group_by(mutant) %>%
      summarise(count = n()) %>%
      knitr::kable( align = 'c', booktabs = TRUE, format = "latex")
  sink()

  sink(file = "../../analysis/count_by_muttype.tex")
  snp %>%
      group_by(mutation_type) %>%
      summarise(count = n()) %>%
      knitr::kable(col.names = c("Type de mutation", "nombre"),
                   align = 'c',
                   booktabs = TRUE, format = "latex")
  sink()

  sink(file = "../../analysis/seq_by_mutant.tex")
  distinct(snp, name, mutant) %>%
      group_by(mutant) %>%
      summarise(count = n()) %>%
      knitr::kable( align = 'c', booktabs = TRUE, format = "latex")
  sink()
#+END_SRC

*** DONE Détermination des SNP calibrés [2/2]
CLOSED: [2015-11-27 Fri 22:56]
- [X] créer la fonction =is_a_position= qui détermine si un SNP est bien à la
  position attendu
- [X] faire la même chose par type de mutant
On veut filtrer les positions qui sont bien les SNP calibrés. 

#+BEGIN_SRC R :tangle ./scripts/variant_analysis.R
  ## ==============================================================================
  ## SNP ATTENDUS OU NON
  ## ==============================================================================
  ##

  ## compte le nombre de SNP par position. hypothèse : un SNP `calibré' génère au
  ## moins 5 SNP parmi toutes les séquences. sortie dans une table qui sert de
  ## query à la fonction =is_position=
  snp %>%
      group_by(offset_on_subject) %>%
      summarise(count = n()) %>%
      ## qplot(data = ., offset_on_subject, count)
      filter(count > 5) %>%
      select(offset_on_subject) %>%
      unlist() %>%
      as.vector() ->
      position_table

  ##' .. content for \description{} (no empty lines) ..
  ##' détermine si la postion sur la séquence de référence est un SNP artificiel
  ##' ou un autre genre de SNP.
  ##' .. content for \details{} ..
  ##' @title is_position
  ##' @param position 
  ##' @param table 
  ##' @return "oui" ou "non"
  is_position <- function(position, table) ifelse(position %in% table, 'oui', 'non')


  snp %>%
      rowwise() %>%
      mutate(position = is_position(offset_on_subject, position_table)) %>%
      ungroup() ->
      snp
#+END_SRC

Le graphique suivant représente la distribution des SNP aux positions
inattendues. 

#+BEGIN_SRC R :tangle ./scripts/variant_analysis.R
  pdf(file = "../../analysis/bgc_en_action.pdf", height = 5.8, width = 8.3)
  snp %>%
      filter(position == "non") %>%
      plot_snp(fill_by = "mutation_type") +
      scale_y_continuous(breaks = c(1, 2)) +
      scale_x_continuous(breaks = position_table, name = waiver()) +
      ggtitle("Substitution aux positions inattendues : biaisees vers GC ?") +
      theme(panel.grid.major.x = element_line(colour = "gray"))
  dev.off()

  sink(file = "../../analysis/bgc_en_action.tex")
  snp %>%
      filter(position == "non") %>%
      group_by(mutation_type) %>%
      summarise(count = n()) ->
      bgc_en_action
  colnames(bgc_en_action) <- c("Type de Substitution", "Nombre")
  print(xtable::xtable( bgc_en_action, align = 'ccc'), include.rownames = FALSE)
  sink()
#+END_SRC

[[file:analysis/bgc_en_action.pdf]]
*** TODO Positions terminales de switch [1/3]
- [ ] voir le test à utiliser pour comparer les distributions
- [ ] comparer les distributions statistiquement, si $n$ est suffisamment grand. 
- [X] Naïvement on utilise ici la position terminale du dernier SNP. Cependant,
  il existe des SNPs qui ne sont pas dans la conversion track, c'est ce qu'on a
  observé. Il faut donc définir une nouvelle fonction =max_pos= qui définit si
  on est bien à un SNP calibré ou non. voir après avoir définit la fonction
  =is_a_position=. => Simplement filtrer par position

On veut ici analyser la distribution des positions terminales de SNP. C'est à dire à quel
endroit on bascule à nouveau sur le génotype sauvage. On ne garde que les
positions qui sont des positions calibrées. 

#+BEGIN_SRC R :tangle ./scripts/variant_analysis.R
  ##==============================================================================
  ## POSITION DE SWITCH
  ##==============================================================================

  pdf(file = "../../analysis/switch_distrib.pdf", height = 5.8, width = 8.3)

  snp %>%
      ## par plasmide -- et par type de mutant
      group_by(name, mutant) %>%
      ## garde seulement les positions calibrées
      filter(position == "oui") %>% 
      ## cherche la postion minimale de SNP
      summarise(offset_on_subject = min(offset_on_subject)) %>% 
      ## represente la distribution
      plot_snp(legend_position = c(0.8, 0.8)) +
      ggtitle("Distribution de la position de switch en fonction du type de mutant") +
      ## superpose les deux distribution pour comparer
      facet_grid( mutant ~ .) 

  dev.off()
#+END_SRC

*** DONE Néomutations [1/1]
CLOSED: [2015-11-27 Fri 23:53]
- [X] rajouter le filtre sur les positions calibrées. 

Le but est de trouver les SNPs aux positions calibrées qui ne sont pas ceux
attendus. Typiquement ce sont les mutations /strong/ dans la manip Weak, et les
mutations /weak/ dans la manip Strong. Si les mutations en questions sont
répétées sur l'ensemble du clone, alors c'est une contamination. Sinon, ce sont
des données intéressantes. 

#+BEGIN_SRC R :tangle ./scripts/variant_analysis.R
  ##============================================================================== 
  ## OUTLIERS
  ##==============================================================================
  ##
  ##' .. content for \description{} (no empty lines) ..
  ##' 
  ##' Détermine si le SNP en question est un outlier ou non, c'est à dire une
  ##' mutation strong chez un mutant weak ou inversement.
  ##' 
  ##' .. content for \details{} ..
  ##' @title is_outlier
  ##' @param mutant : le type de mutant
  ##' @param mutation_type : le type de substitution
  ##' @return 
  is_outlier <- function(mutant, mutation_type)
  {
      if (mutant == 'strong' && mutation_type == 'SW') {
          "non"
      } else if (mutant == 'weak' && mutation_type == 'WS') {
          "non"
      } else {
          'oui'
      }
  }

  snp %>%
      ## par ligne, determine si la position est inattendue
      rowwise() %>%
      mutate(attendu = is_outlier(mutant, mutation_type)) %>%
      ungroup() %>%
      ## garde les positions calibree
      filter(position == "oui") %>% 
      ## sur lesquelles le résultat est inattendu
      filter(attendu == "non") %>%
      plot_snp(legend_position = c(0.2, 0.9)) +
      geom_text(aes(label = name, y = 0.5), check_overlap = TRUE,
                position = "dodge") +
      coord_flip() +
      theme(panel.ontop = FALSE)

  ## sortie des résultats dans un joli tableau latex
  sink( file = "../../analysis/outlier.tex", append = FALSE)
  snp %>%
      rowwise() %>%
      mutate(attendu = is_outlier(mutant, mutation_type)) %>%
      ungroup() %>%
      filter(attendu == "non") %>%
      mutate(position = offset_on_subject, ref = s_base, read = q_base) %>%
      select(-read_name, -offset_on_subject, -s_base, -q_base) %>%
      knitr::kable(format = "latex", booktabs = TRUE)
  sink()

  ## pdf(file = "../../analysis/outliers.pdf", width = 4, height = 2)
#+END_SRC

La liste des constructions qui montrent des néo-mutations :
#+BEGIN_SRC R 
  library(dplyr)

  read.csv("~/stage/seq_novembre/data/variantCalling/snp_table.csv") %>%
    filter(position == "non") %>%
    select(name) %>%
    unique()
#+END_SRC

#+RESULTS:
| pS10-1073 |
| pS24-1073 |
| pS30-1073 |
| pS39-1073 |
| pS5-1073  |
| pS54-1073 |
| pS74-1073 |
| pS82-1073 |
| pS88-1073 |
| pW14-1073 |
| pW19-1073 |
| pW2-1073  |
| pW23-1073 |
| pW35-1073 |
| pW6-1073  |
| pW81-1073 |
| pW87-1073 |
| pW93-1073 |

*** DONE Position des SNP par rapport à la conversion tract [1/1]
CLOSED: [2015-11-27 Fri 23:52]
- [X] Écrire une fonction =is_inside_conv= qui détermine si un SNP est en dehors
  ou en dedans de la conversion tract.
  
#+BEGIN_SRC R :tangle ./scripts/variant_analysis.R
  snp %>%
      ## par exogene
      group_by(name) %>%
      ## garde seulement les positions attendues
      filter(position == "oui") %>%
      ## cherche la borne supérieure et inférieure
      summarise(min = min(offset_on_subject), max = max(offset_on_subject)) %>%
      ## combine avec la table mère
      inner_join(snp, by = "name") ->
      snp
 
  ##' .. content for \description{} (no empty lines) ..
  ##' détermine si le SNP est dans la conversion tract ou non. 
  ##' .. content for \details{} ..
  ##' @title 
  ##' @param query la position requête
  ##' @param min la borne inférieure de la conversion tract
  ##' @param max la borne supérieure de la conversion tract
  ##' @return oui ou non
  is_inside_conv <- function(query, min, max)
  {
      ifelse(min <= query & query <= max, "oui", "non")
  }

  sink(file = "../../analysis/inside_conv.tex")
  snp %>%
      rowwise() %>%
      ## détermine si on est dans la conversion tract ou non
      mutate(inside_conv = is_inside_conv(offset_on_subject, min, max)) %>%
      ungroup() %>%
      ## filtre pour avoir les snp non attendus
      filter(position == "non") %>%
      ## groupe selon qu'on est dans ou en dehors de la CT
      group_by(inside_conv) %>%
      ## compte le nombre de snp par cas
      summarise(count = n()) %>%
      ## format en .tex
      knitr::kable(format = "latex", booktabs = TRUE)
  sink()
#+END_SRC
*** Polymorphisme [2/2]
En analysant visuellement les spectrogrammes aux positions de SNP attendues, on
s'est rendu compte qu'il persistait des variants, et notamment chez les
constructions ~weak~. Dans une première approche, on utilise la qualité de la
position comme proxy du polymorphisme à cette position. En effet, l'algorithme
de quality-calling est très sensible aux polymorphismes, autrement dit à la
présence de pics parasites. On peut donc raisonnablement se dire que les SNP de
faible qualité, notamment en fin de conversion tract, correspondent à des SNP
hétérogènes. Ce qui pourrait s'expliquer par une absence de réparation à la
génération 0, mais que les descendants 01 et 02 réparent chacun d'une façon
différente.

**** DONE Graphiquement
CLOSED: [2015-12-03 Thu 19:47]
On veux étudier le polymorphisme aux positions calibrées. Comme on ne peut pas
avoir accès aux données trace par trace, on utilise la qualité  comme proxy du
polymorphisme. 

#+BEGIN_SRC R :tangle ./scripts/variant_analysis.R
  pdf(file = "../../analysis/qualite_distrib.pdf", height = 5.8, width = 8.3)
  snp %>%
      filter(position == "oui") %>%
      qplot(data = ., x = offset_on_subject, y = q_qual, color = mutant,
            alpha = 0.1) +
      theme_minimal(base_family = "Courier") +
      scale_color_brewer(palette = "Set2", name = "") +
      scale_alpha_continuous(guide = FALSE, name = "") + 
      xlab("Position") + ylab("qualite") +
      scale_x_continuous(breaks = position_table) +
      theme(legend.position = c(0.5, 0.2),
            axis.text = element_text(size = 8, colour = "gray"))
  dev.off()
#+END_SRC

[[./analysis/qualite_distrib.pdf]]

Aux positions inférieures à 700bp, la qualité de certains SNP diminue, notamment
chez les WEAK. En fait quasiment exclusivement dans la construction WEAK. Aux
positions supérieures à 700bp, il y a également des baisses de qualité pour les
constructions STRONG. Difficile à ce stade de déterminer s'il s'agit de bruit ou
de signal. 

L'inconvénient de cette approche par la qualité est qu'elle ne permet pas de
connaître la nature de la base correspondant au signal "parasite". Or, lorsqu'on
observe les spectrogrammes visuellement, souvent, le signal qui persiste est
celui attendu dans la séquence sauvage. Autrement dit, lorsque le gène
synthétique oppose un allèle W à un allèle sauvage S, d'une manière ou d'une
autre, le signal sauvage S persiste dans la population descendante que l'on
séquence. 

**** DONE Fréquence des bases polymorphes associées aux SNP attendus
CLOSED: [2016-01-06 Wed 08:22]

#+BEGIN_SRC R :tangle ./scripts/variant_analysis.R
  sink("../../analysis/freq_polymorphism.tex")
  snp %>%
      filter(position == "oui", q_qual < 40, offset_on_subject < 600) %>%
      group_by(mutant) %>%
      summarise(count = n()) %>%
      knitr::kable(format = "latex", booktabs = TRUE)
  sink()

  snp %>%
      filter(position == "non", q_qual < 40, offset_on_subject < 600) #%>%
      group_by(mutant) %>%
      summarise(count = n())# %>%
      knitr::kable(format = "latex", booktabs = TRUE)

  snp %>%
    mutate(name = gsub("-1073", "", x = name)) %>%
    filter(position == "oui", q_qual < 40, offset_on_subject < 600) %>%
    group_by(name) %>%
    summarise(count = n()) -> #%>%
    ## filter(count > 1) ->
    candidats

  snp %>%
    filter(name == "pW6-1073") %>%
    qplot(data = .,
          x = offset_on_subject,
          y = q_qual,
          geom = "line",
          xlim = c(0, 750)) +
    geom_vline( xintercept = 456, color = "red") +
    geom_vline(xintercept = position_table,
               color = "blue",
               alpha = 0.2)

  snp %>%
    mutate(name = gsub("-1073", "", x = name)) %>%
    filter(name %in% candidats$name) %>%
    ggplot(data = .,
           aes(x = offset_on_subject, y = q_qual,
               colour = name)) +
    geom_line() +
    facet_grid(name~mutant) +
    theme_minimal() +
    theme(text = element_text(size = 6))

  ggsave(filename = "~/stage/seq_novembre/analysis/candidats_heterozygotes.pdf",
         width = 29.7, height = 21, units = "cm")
#+END_SRC

--- 

*** Sauvegarde du tableur
#+BEGIN_SRC R :tangle ./scripts/variant_analysis.R
  write.csv(snp, file = "snp_table.csv", quote = FALSE)
#+END_SRC
* Analyse des positions hétérozygotes
# #+TOC: headlines 2 local

L'approche précédente utilisait la qualité comme proxy du polymorphisme aux
positions de SNP attendues. Dans cette seconde approche, le but est de
déterminer la nature du pic parasite, et de déterminer s'il correspond ou non à
une persistance de l'allèle sauvage dans la descendance du recombinant. 

Le but est d'obtenir un tableau qui aurait la forme suivante :

|  A | C | T |   G | prim | prim_score | sec | sec_score | ratio | position | gene_synt | wt |
|----+---+---+-----+------+------------+-----+-----------+-------+----------+-----------+----|
| 90 | 0 | 0 | 120 | G    |        120 | A   |        90 |   120 |      437 | G         | A  |

Le programme [[http://www.nybg.org/files/scientists/dlittle/polySNP.html][polySNP]] fait justement ça très bien.
** Bascule des fichiers mal appelés
Le but de ce script est de repasser les fichiers du tableau suivant dans les
bonnes catégories, de façon à ce qu'ils soient alignés avec la bonne référence. 

| nom    | type     |
|--------+----------|
| "pS60" | "weak"   |
| "pS83" | "weak"   |
| "pS92" | "weak"   |
| "pS91" | "weak"   |
| "pW6"  | "strong" |

Je n'ai pas choisi la méthode la plus subtile. Ça fera le taf, pour l'instant. 

#+BEGIN_SRC sh ./scripts/recaller.sh
  #!/bin/bash

  ## TODO peut-être trouver une solution plus "élégante…"

  cd ~/stage/seq_novembre/data

  cd ./spectrograms

  mv pS60-1073.ab1 pW600-1073.ab1
  mv pS83-1073.ab1 pW830-1073.ab1
  mv pS92-1073.ab1 pW920-1073.ab1
  mv pS91-1073.ab1 pW910-1073.ab1
  mv  pW6-1073.ab1 pS600-1073.ab1
#+END_SRC

** Base calling
Le but de cet étape est de déterminer, pour chaque position, par séquence, qui
est la base majoritaire, la confiance qu'on peut lui attribuer, la base
secondaire, la confiance qu'on peut lui attribuer, ainsi que le ratio des
deux scores de confiance. 

*** via sangerseqR
Dans un premier temps, j'ai voulu prototypé l'analyse et le résultat attendu
dans R, en utilisant le package ~sangerseqR~ (voir la documentation [[https://www.bioconductor.org/packages/release/bioc/html/sangerseqR.html][là]]). 

#+BEGIN_SRC R :tangle ./scripts/sangerseq.R
  ## ------------------------------------------------------------------------------
  ##                                   BASE CALLING
  ## ------------------------------------------------------------------------------

  setwd("~/stage/seq_novembre/data/tmp/")
  library(dplyr)
  library(sangerseqR)
  library(Biostrings)

  ## la deuxième ligne du fichier reference.fasta contient la séquence de
  ## référence. Elle est convertie en un objet DNA string.
  ref <- readLines("../reference.fasta")[2] %>%
    DNAString() %>%
    reverseComplement()

  ##' .. content for \description{} (no empty lines) ..
  ##' Call bases on a query, based on primary and secondary traces.
  ##' .. content for \details{} ..
  ##' @title baseCaller
  ##' @param query the ab1 file name.
  ##' @param ref the reference. a DNAString object.
  ##' @return a sangerseqR object.
  baseCaller <- function(query, ref)
  {
    readsangerseq(query) %>%
      makeBaseCalls(ratio = 0.5)#  %>%
      ## setAllelePhase(obj = ., refseq = ref)
  }

  pW85 <- baseCaller(query = "../spectrograms/pW85-1073.ab1", ref = ref) #TEST:

  ##' .. content for \description{} (no empty lines) ..
  ##' Attribue le nom des bases à chaque trace.
  ##' .. content for \details{} ..
  ##' @title get_peak_matrix
  ##' @param  obj un objet sangerseq. 
  ##' @return tbl_df object
  get_peak_matrix <- function(obj)
  {
    obj %>%
      peakAmpMatrix() %>%
      as.data.frame() %>%
      select(A = V1, C = V2, G = V3, T = V4) %>%
      tbl_df()
  }

  ##' .. content for \description{} (no empty lines) ..
  ##' 
  ##' Une fonction qui permet de déterminer la base qui a le pic le plus haut, la
  ##' hauteur de son pic, la base avec le second pic le plus haut, la hauteur de
  ##' ce pic, et le ratio des deux, ainsi que la position dans le référentiel de
  ##' la séquence.
  ##' 
  ##' .. content for \details{} ..
  ##' @title get_score_matrix
  ##' @param data typiquement une dataframe crée avec get_peak_matrix()
  ##' @return une dataframe
  get_score_matrix <- function(data)
  {
    data.frame(
      ## renvoit un vecteur avec le nom des bases avec le pic le plus haut        
      primaire = apply(data, 1, function(n) which.max(n) %>% names()),
      ## renvoit un vecteur avec le score du pic le plus haut
      prim_score = apply(data, 1, function(n) max(n)),
      ## renvoit un vecteur avec le nom des bases au second pic
      second = apply(data, 1, function(n) which.max(n[n != max(n)]) %>% names()),
      ## renvoit un vecteur avec le score du second pic 
      sec_score = apply(data, 1, function(n) sort(n)[length(n) - 1])
    ) %>%
      mutate(ratio = sec_score / prim_score,
             seq_position = row.names(.) %>% as.numeric())
  }

  pW85 %>%
    get_peak_matrix() %>%
    get_score_matrix() %>%
    tbl_df() ->
    test_data

  theme_set(theme_minimal())

  test_data %>%
    ggplot(aes(x = seq_position, y = prim_score)) +
    geom_path(aes(color = primaire)) +
    geom_path(aes(y = sec_score, color = second)) +
    facet_grid(primaire ~ .) 
    ## xlim(c(180, 220))

#+END_SRC

*** via phred
Brent Ewing m'a ensuite envoyé le code source de phred [2016-01-08 Fri], que
j'ai pu installer sur le mac et sur la virtualbox biolinux. C'est l'une des
dépendances principale de ~polySNP~, un programme qui permet de produire
exactement le résultat sous la forme attendue.

Le script suivant effectue le base-calling avec phred directement. 

#+BEGIN_SRC sh :tangle ./scripts/base-call-phred.sh
  #!/usr/local/bin/bash

  #### PHRED BASE CALLING

  ### utilise phred pour le base call des spectrogrammes. Ce qui nous interésse
  ### ici n'est pas tant le base call en soi que les contrôles de qualité et
  ### surtout la détection des bases polymorphes.

  cd ~/stage/seq_novembre/data/

  # NOT RUN : mkdir quality phred poly

  phred \
      ## emplacement des fichiers
      -id ./spectrograms \
      ## trim les bases à gauche et droite en fonction de la qualité
      -trim_alt "" \
      ## selon la probabilité d'erreur suivante.
      -trim_cutoff 0.05 \
      ## écrit les séquences trimmées dans un fichier phred
      -trim_phd \
      ## sortie des fichiers de qualité dans le dossier quality au format .qual
      -qd ./quality \
      ## sortie des séquences dans le dossier quality au format .qual
      -pd ./phred \
      ## sortie des positions polymporphiques dans le dossier poly.
      -dd ./poly
#+END_SRC

*** via polySNP
PolySNP effectue exactement le même procédé. Il nécessite une étape antérieure
d'alignement entre deux séquences, la séquence sauvage et la séquence porteuse
des SNP, au format fasta. Le but est de déduire les positions de SNP, pour
ensuite aligner les séquences en sortie de phred avec cet alignement de
référence.

**** alignement des références
Cet alignement est effectué avec le programme EMBOSS ~needle~, qui utilise
l'algorithme de Needleman-Wunsch. L'alignement se fait sur toute la longueur des
séquences. Dans un premier temps, j'utilisais la séquence référence non
corrigée, mais elle semble présenter un indel à la position. Il faut de plus
utiliser le /reverse complement/ des séquences de référence, autrement muscle se
perd dans l'étape d'alignement. 
#+BEGIN_SRC sh :tangle ./scripts/aligne_reference_snp.sh
  #!/bin/bash
  ##
  ##
  cd ~/stage/seq_novembre/data

  needle                                \
      -asequence ./ref/wt_corrected.fst \
      -sformat1 fasta                   \
      -sreverse1                        \
      -bsequence ./ref/strong.fst       \
      -sformat2 fasta                   \
      -sreverse2                        \
      -outfile ./ref/aln-strong-wt.fst  \
      -aformat3 fasta                   \
      -gapopen 10.0                     \
      -gapextend 0.5

  needle                                \
      -asequence ./ref/wt_corrected.fst \
      -sformat1 fasta                   \
      -sreverse1                        \
      -bsequence ./ref/weak.fst         \
      -sformat2 fasta                   \
      -sreverse2                        \
      -outfile ./ref/aln-weak-wt.fst    \
      -aformat3 fasta                   \
      -gapopen 10.0                     \
      -gapextend 0.5
#+END_SRC

**** documentation polySNP

La documentation du programme =polySNP=. 

#+BEGIN_QUOTE
~reference_file~ is a FASTA format file containing two aligned sequences (SNPs
will be inferred)

~trace_file~ is a chromatogram file readable by PHRED or convert_trace

~standard_curve_file~ is a CSV text file containing reference position (in
~reference_file~), reference base, slope (decimal notation), y–intercept

~-l~ outputs a line of data labels before outputting the data

~-a~ outputs the alignment along with the data

~-p~ 0 base call and trim with PHRED, use PHRED values for peak area measurement
-(default)

~-p~ 1 base call and trim with PHRED, use PHRED values for peak height
-measurement

~-p~ 2 base call and trim with PHRED, use BIO::SCF values for peak height
-measurment

~-p~ 3 use existing base calls, trim with qclip, use BIO::SCF values for peak
-height measurement

For ~-p~ 0, 1, or 2 an optional ~-c~ 0.XX argument can be appended to specify the
PHRED “-trim_cutoff” value. If no ~-c~ 0.XX value is specified, the script
defaults to 0.10.
#+END_QUOTE

Étant donné la façon dont polySNP traite les chemins de fichiers, il faut que
les fichiers en cours d'analyse soient dans le dossier courant.

- [X] peut-être utiliser des softlinks, ou alors carrément copier les différents
  documents dans un dossier de travail réservé.
**** clones weak

Le script suivant permet d'obtenir le tableau de résultat pour les clones weak.
#+BEGIN_SRC sh :tangle scripts/polysniper-weak.sh
  #!/bin/bash 

  ####
  #### POLYSNP
  ####
  ###
  ### Ce script qui effectue le base-calling via phred, détermine les
  ### positions de SNP qui sont aux positions attendues d'après les alignements de
  ### référence, et détermine pour chaque position attendue les deux bases
  ### appelées à chaque pic.

  cd ~/stage/seq_novembre/data/snp-calling/weak

  ## copie l'alignement référence dans .
  cp ../../ref/aln-weak-wt.fst .

  for spectro in ../../spectrograms/pW*.ab1
  do
      cp $spectro .
      polySNP \
          -r aln-weak-wt.fst \
          -t `basename $spectro` \
          -p 0 \
          -c 0.05
      rm ./`basename $spectro`
  done
#+END_SRC

**** clones strong
Le script suivant permet d'obtenir le tableau de résultat pour les clones strong.
#+BEGIN_SRC sh :tangle scripts/polysniper-strong.sh
  #!/bin/bash 

  ####
  #### POLYSNP
  ###
  ### le script qui effectue le base-calling via phred, qui détermine les
  ### positions de SNP qui sont aux positions attendues d'après les alignements de
  ### référence, et qui détermine pour chaque position attendue les deux bases
  ### appelées à chaque pic.

  cd ~/stage/seq_novembre/data/snp-calling/strong

  ## copie l'alignement référence dans .
  cp ../../ref/aln-strong-wt.fst .

  for spectro in ../../spectrograms/pS*.ab1
  do
      cp $spectro .
      polySNP \
          -r aln-strong-wt.fst \
          -t `basename $spectro` \
          -p 0 \
          -c 0.05
      rm ./`basename $spectro`
  done
#+END_SRC

**** tous les clones
Le script suivant permet d'obtenir les deux tableaux de résultats, et élimine
les lignes vides. (temps d'exécution approximatif : 2min.)

#+BEGIN_SRC sh :tangle scripts/polysniper.sh
  #!/bin/bash

  # NOT RUN : mkdir snp-calling snp-calling/weak snp-calling/strong

  cd ~/stage/seq_novembre/data/snp-calling

  # crée la table de résultat pour weak et strong.
  ../../scripts/polysniper-weak.sh > weak/weak-polysnp.csv
  ../../scripts/polysniper-strong.sh > strong/strong-polysnp.csv

  # enlève les lignes vides dans les deux fichiers.
  sed -i '/^$/d' weak/weak-polysnp.csv
  sed -i '/^$/d' strong/strong-polysnp.csv

  # enlève les champs mal formattés (ie une virgule dans le champ commentaire.
  # dans un fichier csv. malin...)
  # prepend header.csv describing fields to results
  # table and remove space
  { head -n 1 header.csv | sed 's/ /\./g' ;          \
    cat weak/weak-polysnp.csv | sed 's/,\ / /g' }  | \
      cat > weak.csv

  { head -n 1 header.csv | sed 's/ /\./g' ; \
    cat strong/strong-polysnp.csv | sed 's/,\ / /g' } | \
      cat > strong.csv
#+END_SRC
** Analyses 
*** Boilerplate
#+BEGIN_SRC R :tangle scripts/polysnip-read.R
  setwd("./data/snp-calling")
  library(dplyr)
  library(ggplot2)
  library(viridis)

  theme_set(theme_gray(base_size = 9, base_family = "Courier") +
            theme(panel.grid.major.y = element_line(size = 1, color = "white"),
                  panel.grid.major.x = element_blank(),
                  panel.grid.minor.x = element_blank()))
#+END_SRC  

*** get and clean data
~polySNP~ introduit une colonne de commentaire, bien trop longue, remplacée par
un facteur à quatre niveaux. 

| facteur | commentaire                                           |
|---------+-------------------------------------------------------|
| D       | WARNING: bases could not be matched                   |
| C       | WARNING: multiple peak span, data are not trustworthy |
| B       | WARNING: primary peak does not match the reference    |
| A       | processed normally                                    |

#+BEGIN_SRC R :tangle scripts/polysnip-read.R
  read_polysnp <- function(filename)
  {
    read.csv(filename, stringsAsFactors = FALSE) %>%
      tbl_df() %>%
      select(
        -datum,
        -analysis,
        -corrected.proportion.A,
        -corrected.proportion.B,
        -uncorrected.proportion.B,
        name   = file,
        refpos = reference.position,
        qpos   = SCF.position,
        wt     = A.base,
        snp    = B.base,
        first  = first.call,
        second = second.call,
        ratioA = uncorrected.proportion.A,
        farea  = first.area,
        sarea  = second.area
      ) %>%
      mutate(name = gsub("-1073.ab1", "", x = name),
             comments = factor(comments))
  }

  ## combine les données en une table unique, ajoute l'info du type de mutant.
  ## TODO corriger les mutants dans la mauvaise catégorie.
  snp <- rbind(
    read_polysnp("weak.csv") %>% mutate(mutant = "weak") %>% tbl_df(),
    read_polysnp("strong.csv") %>% mutate(mutant = "strong") %>% tbl_df()
  )

  ## réaffecte les niveaux de facteur. 
  ##
  ## +---------+-------------------------------------------------------+
  ## | facteur | commentaire                                           |
  ## |---------+-------------------------------------------------------|
  ## | D       | WARNING: bases could not be matched                   |
  ## | C       | WARNING: multiple peak span, data are not trustworthy |
  ## | B       | WARNING: primary peak does not match the reference    |
  ## | A       | processed normally                                    |
  ## +---------+-------------------------------------------------------+

  ## il n'y a pas dans les données de facteur C. d'où les trois niveaux de
  ## facteur. sensible aux variations de paramètre polySNP à mon avis. à
  ## surveiller.
  snp$comments <- plyr::mapvalues(snp$comments,
                                  from = levels(snp$comments),
                                  to = c("D", "A", "B"))

  ## correct NA symbol
  snp$second[snp$second == "-"] <- NA

  ## corrige les erreurs de SNP. 
  snp$mutant[snp$name == "pS60"] <- "weak"
  snp$mutant[snp$name == "pS83"] <- "weak"
  snp$mutant[snp$name == "pS92"] <- "weak"
  snp$mutant[snp$name == "pS91"] <- "weak"
  snp$mutant[snp$name == "pW6" ] <- "strong"
#+END_SRC

*** compte le nombre de séquence avec SNP_II par position
#+BEGIN_SRC R :tangle scripts/polysnip.R
  snp %>%
    filter(!is.na(second)) %>%
    ggplot(aes(x = refpos, fill = mutant)) +
    geom_histogram(binwidth = 10) +
      facet_grid(mutant~.) +
      scale_fill_discrete(guide = FALSE) +
      xlab("Position sur la sequence de reference") + 
      ylab("")
  ggsave("../../analysis/mutant-count.pdf")
#+END_SRC 

*** compte le nombre de séquence avec SNP_II de nature ATCG par position
#+BEGIN_SRC R :tangle scripts/polysnip.R
  snp %>%
    filter(!is.na(second)) %>%
    filter(comments == "A") %>%
    group_by(refpos, mutant, second) %>%
    summarise(count =n()) %>%
    ggplot(aes(x = refpos, y = count, color = second, fill = second)) +
    geom_point() +
    geom_bar(stat = "identity", alpha = 0.2) +
    facet_grid(mutant~second) +
    xlab("Position sur la sequence de reference") +
    ylab("Nombre de sequence") +
    scale_fill_discrete(guide = FALSE) +
    scale_colour_discrete(guide = FALSE) 
  ggsave("../../analysis/mutant-second.pdf")
#+END_SRC

*** idem, avec un filtre sur le ratio des pics > 0.2
#+BEGIN_SRC R :tangle scripts/polysnip.R
  snp %>%
    filter(!is.na(second)) %>%
    filter(comments == "A") %>%
    filter(ratioA > 0.2) %>%
    group_by(refpos, mutant, second) %>%
    summarise(count =n()) %>%
    ggplot(aes(x = refpos, y = count, color = second, fill = second)) +
    geom_point() +
    geom_bar(stat = "identity", alpha = 0.2) +
    facet_grid(mutant~second) +
    xlab("Position sur la sequence de reference") +
    ylab("Nombre de sequence") +
    scale_fill_discrete(guide = FALSE) +
    scale_colour_discrete(guide = FALSE) 
  ggsave("../../analysis/mutant-second-filter.pdf")
#+END_SRC

*** distribution de la longueur de la tract de conversion
#+BEGIN_SRC R :tangle scripts/polysnip.R
  snp %>%
    rowwise() %>%
    filter(first == snp) %>%
    ungroup() %>%
    group_by(name, mutant) %>%
    summarise(debut = min(refpos), fin = max(refpos), longueur = fin - debut) %>%
  ## print() %>%
  inner_join(x = snp, y = .)

    ggplot(aes(x = longueur, fill = mutant)) +
    geom_histogram(binwidth = 10) +
    facet_grid(mutant~.) +
    theme_minimal(base_family = "Courier") +
    theme(panel.ontop = TRUE,
          panel.grid.major.y = element_line(size = 1, color = "white"),
          panel.grid.minor.y = element_line(size = 0.5, color = "white")) +
    xlab("Distribution de la longueur de la tract de conversion") +
    ylab("")
#+END_SRC

*** distribution de la longueur des séquences
#+BEGIN_SRC R :tangle scripts/polysnip.R
  snp %>%
    group_by(name) %>%
    summarise(max = max(qpos)) %>%
    qplot(data =., max, binwidth = 1) +
    xlab("Distribution de la longueur des séquences") 
#+END_SRC
*** extraction de la séquence IUPAC
#+BEGIN_SRC R :tangle scripts/polysnip.R
  mergeiupac <- function(first, second)
  {
    if(is.na(second)) { Biostrings::mergeIUPACLetters(paste0(first, "" )) }
    else { Biostrings::mergeIUPACLetters(paste0(first, second)) }
  }

  snp %>%
    filter(comments == "A") %>%
    rowwise() %>%
    mutate(type = mergeiupac(first, second)) %>%
    select(name, type) %>% 
    ungroup() -> seqlist 

  lapply(
    split(seqlist, seqlist$name), # split by name
    function(x) { 
      paste0( 
        ">", x$name[1], "\n", # copie le nom de la sequence avec le fasta sep
        gsub(x = toString(x$type), # et la sequence iupac
             pattern = ", ",
             replace = "" ))
    }
  ) %>%
    unlist() ->
    seqlist


  ## 1. concatenate sequence
  ## 2. prepend sequence name.

  snp %>%
    select(wt, refpos) %>%
    arrange(refpos) %>%
    unique() %>%
    {
      toString(.$wt) %>% gsub(x = ., pattern = ", ", replace = "")
    } %>%
    paste0(">wt", "\n", .) ->
    refsnp

  cat(c(refsnp, seqlist), sep = "\n",
      file = "iupac_seqlist.fasta")

  snp %>% filter(qpos == "457")

  snp %>%
    rowwise() %>%
    filter(first != snp & first != wt) %>%
    qplot(data = ., refpos, geom = "histogram")

    select(first) %>%
    {
      as.factor(.$first) %>% levels()
    }
#+END_SRC
** Analyses de la répartition des sites polymorphes sur les reads
Les graphes précédents semblent montrer que les sites polymorphes sont plus
nombreux chez les weak que chez les strongs. 

On veut voir la responsabilité relative des clones dans le compteur de site
polymorphe. Certains clones pourraient avoir beaucoup de sites polymorphes,
d'autres peu. Ou alors la distribution des sites polymorphes est assez équitable
entre les reads. 

#+BEGIN_SRC R :tangle scripts/polysnip-repartition-site.R
  source("scripts/polysnip-read.R")

  snp %>%
    filter(!is.na(second)) %>%
    ## rowwise() %>%
    ## filter(first == snp) %>%
    ## ungroup() %>%
    group_by(name, mutant) %>%
    summarise(count = n()) %>%
    filter(count > 10)


    ggplot(aes(x = count)) +
    geom_histogram(binwidth = 1) +
    facet_grid(mutant~.)

  snp %>%
    filter(name == "pS96")
#+END_SRC

Une liste de sequence avec beaucoup de polymorphismes SNP par reads :
 
| name  | mutant | count |
| (chr) | (chr)  | (int) |
|-------+--------+-------|
| pS96  | strong |    15 |
| pW29  | weak   |    14 |
| pW35  | weak   |    17 |
| pW5   | weak   |    15 |
| pW68  | weak   |    15 |
| pW69  | weak   |    21 |
| pW83  | weak   |    15 |

** Distribution des ratios par read
#+BEGIN_SRC R :tangle scripts/polysnip-repartition-site.R

#+END_SRC

** Vérification des séquences alignées
#+BEGIN_SRC R :tangle scripts/polysnip-repartition-site.R
  ## charge le dataset avec les snp, nettoie les données.
  source("scripts/polysnip-read.R")

  #' Cette fonction transforme deux bases accolées dans le code IUPAC d'ambiguité
  #' de séquence.
  #' @param first la base du pic majoritaire
  #' @param second la base du pic majoritaire.
  mergeiupac <- function(first, second)
  {
    if(is.na(second)) { Biostrings::mergeIUPACLetters(paste0(first, "" )) }
    else { Biostrings::mergeIUPACLetters(paste0(first, second)) %>% tolower() }
  }

  ## prend les données où l'alignement s'est fait de façon normale
  snp %>%
    filter(comments == "A") %>%
    rowwise() %>%
    mutate(type = mergeiupac(first, second)) %>%
    ungroup() ->
  snp

  ## définit le thème par défault des plots
  theme_set(theme_minimal(base_size = 8, base_family = "Courier") +
    theme(panel.grid.major.y = element_line(colour = "gray", linetype = "dotted"),
          panel.grid.minor.y = element_line(colour = "gray", linetype = "dotted"),
          panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank())
  )

  #' cette fonction définit si une base est strong ou weak. Si la base en question
  #' est NA, alors renvoit un charactere vide.
  #' @param base : une base d'ADN.
  base_caller <- function(base)
  {
    if (is.na(base)) { "" }
    else if (base == "A" || base == "T") { "W" }
    else { "S" }
  }


  ## détermine dans une colonne `longueur` la longueur de la trace de conversion.
  snp %>%
    rowwise() %>%
    filter(first == snp) %>%
    ungroup() %>%
    group_by(name, mutant) %>%
    summarise(debut = min(refpos), fin = max(refpos), longueur = fin - debut) %>%
    inner_join(x = snp, y = .) ->
  snp

  snp %>%
    filter(mutant == "weak") %>%
    arrange(longueur) %>%
    {.$name %>% unique()} ->
  weak_by_length

  snp %>%
    filter(mutant == "strong") %>%
    arrange(longueur) %>%
    {.$name %>% unique()} ->
  strong_by_length

  snp %>%
    filter(mutant == "strong") %>%
    rowwise() %>%
    mutate(firsttype  = base_caller(first),
           secondtype = base_caller(second)) %>%
    ungroup() %>%
    ggplot(aes(x     = factor(refpos),
               y     = factor(name, levels = strong_by_length),
               label = paste0(firsttype, secondtype),
               fill = firsttype)) +
    geom_tile(alpha = 0.2) +
    geom_text(aes(
      color = factor(paste0(firsttype, secondtype))),
      size = 2,
      family = "Courier",
      fontface = "bold") +
    scale_fill_brewer(palette = "Dark2") +
    scale_color_brewer(palette = "Dark2") +
    xlab("Position sur la sequence de reference") +
    ylab("") +
    ggtitle("Constructions Strong") +
    guides(colour = "none", fill = guide_legend(title = "")) +
    theme(legend.position = "bottom")

  ggsave("../../analysis/alignement_pics_strong.pdf")

  snp %>%
    filter(mutant == "weak") %>%
    rowwise() %>%
    mutate(firsttype  = base_caller(first),
           secondtype = base_caller(second)) %>%
    ungroup() %>%
    ggplot(aes(x     = factor(refpos),
               y     = factor(name, levels = weak_by_length),
               label = paste0(firsttype, secondtype),
               fill = firsttype)) +
    geom_tile(alpha = 0.2) +
    geom_text(aes(
      color = factor(paste0(firsttype, secondtype))),
      size = 2,
      family = "Courier",
      fontface = "bold") +
    scale_fill_brewer(palette = "Dark2") +
    scale_color_brewer(palette = "Dark2") +
    xlab("Position sur la sequence de reference") +
    ylab("") +
    ggtitle("Constructions Weak") +
    guides(colour = "none", fill = guide_legend(title = "")) +
    theme(legend.position = "bottom")

  ggsave("../../analysis/alignement_pics_weak.pdf")
#+END_SRC

** Comparaison du polymorphisme SNP / ΦSNP
Les graphes précédents semblent montrer que les positions polymorphes sont
plus nombreuses dans les constructions weak que dans les constructions strong. 
L'idée suivante est de tester la différence entre le nombre de sites polymorphes
spécifiques aux SNP qu'on introduit et le nombre de sites polymorphes aux sites
non-snp. Le but est de déterminer si les polymorphismes qu'on voit sont
spécifiques des SNP. 

Je veux essayer de reproduire l'algorithme de polySNP, de façon à pouvoir
obtenir dans un seul tableau de donnée tous les sites polymorphes, qu'ils
soient SNP ou non, de façon à pouvoir comparer leur distribution.  

#+BEGIN_SRC sh :tangle scripts/polysnp2csv
  #!/bin/bash

  cd ../data/snp-calling/strong

  ## copie l'alignement référence dans .
  cp ../../ref/aln-strong-wt.fst .
  cp ../../ref/aln-weak-wt.fst .

  for spectro in ../../spectrograms/pS*.ab1
  do
      # `basename $spectro`=`basename $spectro`
      cp $spectro .
      ../../../tools/polySNP/polySNP \
          -r aln-strong-wt.fst \
          -t `basename $spectro` \
          -p 0 \
          -c 0.05 \
          > `basename $spectro`.snp

      ## ============
      ## fichier SNP
      ## ============
      #
      # prend la première ligne de l'en tête des sorties de polySNP
      # remplace les espaces par des .
      # prend la sortie de polysnp,
      # supprime les lignes vides,
      # ajoute un champ ,snp
      # remplace les virgule espace par des espaces
      # sortie dans un fichier csv.

      { ( head -n 1 ../header-snp.csv | sed 's/ /\./g' ) ; \
        ( sed '/^$/d;s/$/,snp/;s/,\ / /g' `basename $spectro`.snp ) \
      } | cat > `basename $spectro`.snp.csv

      ## ============
      ## fichier PHD
      ## ============
      #
      # prend l'en-tête de phd,
      # prend la sortie de phd,
      # ne garde que les lignes entre begin_dna et end_dna, non incluses,
      # remplace les ` ` par des `,`
      # sortie dans un fichier csv.

      { ( head -n 1 ../header-phd.csv ) ; \
        ( awk '/BEGIN_DNA/{flag=1;next}/END_DNA/{flag=0}flag' \
              `basename $spectro`.phd.1 | \
                sed -e "s/ /,/g;s/$/,strong,`basename $spectro`/" ) \
      } | cat > `basename $spectro`.phd.csv

      ## ============
      ## fichier POLY
      ## ============
      #
      # prend la sortie poly de phd,
      # ne prend que la dernière ligne,
      # remplace les doubles espaces par des ,
      # ajoute un champ poly
      # compte la position dans la séquence (ie nombre de ligne dans le fichier)
      # sortie dans le fichier poly.

      { ( head -n 1 ../header-poly.csv ) ; \
        ( tail -n +2 `basename $spectro`.poly | \
                sed 's/  /,/g;s/$/,poly/' | \
                awk '$0=1+i++","$0' ) \
      } | cat > `basename $spectro`.poly.csv

      ## ============
      ##   POOLING
      ## ============
      # join les fichiers phd et poly sur la base de la position dans le
      # spectrogramme. join les fichiers obtenus sur la base de la position dans la
      # séquence du tracefile.
      # sortie dans un fichier csv.

      csvjoin -c "position,positionCalledBase" --left \
              `basename $spectro`.phd.csv `basename $spectro`.poly.csv | \
          csvjoin -c "position, sposition" --left \
                  - `basename $spectro`.snp.csv > `basename $spectro`.csv
  done

  ## ================================================================================
  ##                                       WEAK
  ## ================================================================================

  for spectro in ../../spectrograms/pW*.ab1
  do
      # `basename $spectro`=`basename $spectro`
      cp $spectro .
      ../../../tools/polySNP/polySNP \
          -r aln-weak-wt.fst \
          -t `basename $spectro` \
          -p 0 \
          -c 0.05 \
          > `basename $spectro`.snp

      ## ============
      ## fichier SNP
      ## ============
      #
      # prend la première ligne de l'en tête des sorties de polySNP
      # remplace les espaces par des .
      # prend la sortie de polysnp,
      # supprime les lignes vides,
      # ajoute un champ ,snp
      # remplace les virgule espace par des espaces
      # sortie dans un fichier csv.

      { ( head -n 1 ../header-snp.csv | sed 's/ /\./g' ) ; \
        ( sed '/^$/d;s/$/,snp/;s/,\ / /g' `basename $spectro`.snp ) \
      } | cat > `basename $spectro`.snp.csv

      ## ============
      ## fichier PHD
      ## ============
      #
      # prend l'en-tête de phd,
      # prend la sortie de phd,
      # ne garde que les lignes entre begin_dna et end_dna, non incluses,
      # remplace les ` ` par des `,`
      # sortie dans un fichier csv.

      { ( head -n 1 ../header-phd.csv ) ; \
        ( awk '/BEGIN_DNA/{flag=1;next}/END_DNA/{flag=0}flag' \
              `basename $spectro`.phd.1 | \
                sed -e "s/ /,/g;s/$/,weak,`basename $spectro`/" ) \
      } | cat > `basename $spectro`.phd.csv

      ## ============
      ## fichier POLY
      ## ============
      #
      # prend la sortie poly de phd,
      # ne prend que la dernière ligne,
      # remplace les doubles espaces par des ,
      # ajoute un champ poly
      # compte la position dans la séquence (ie nombre de ligne dans le fichier)
      # sortie dans le fichier poly.

      { ( head -n 1 ../header-poly.csv ) ; \
        ( tail -n +2 `basename $spectro`.poly | \
                sed 's/  /,/g;s/$/,poly/' | \
                awk '$0=1+i++","$0' ) \
      } | cat > `basename $spectro`.poly.csv

      ## ============
      ##   POOLING
      ## ============
      # join les fichiers phd et poly sur la base de la position dans le
      # spectrogramme. join les fichiers obtenus sur la base de la position dans la
      # séquence du tracefile.
      # sortie dans un fichier csv.

      csvjoin -c "position,positionCalledBase" --left \
              `basename $spectro`.phd.csv `basename $spectro`.poly.csv | \
          csvjoin -c "position, sposition" --left \
                  - `basename $spectro`.snp.csv > `basename $spectro`.csv
  done
#+END_SRC

CHAMPAAAAAAAAAAAAAAAAAAGNE ! J'ai réussi [2016-01-29 Fri] ! Il suffisait de
modifier deux lignes de commandes dans le script polySNP.

#+BEGIN_SRC sh
  cd ./data/snp-calling/

  csvstack ./strong/*.ab1.csv > huge-strong.csv
#+END_SRC

Le script suivant permet d'analyser les premières données obtenues avec pW85,
dans R. 

Le fichier =phd= garde la trace de la position (dans le champ /position/) dans
le chromatogramme, avec un système de coordonnées qui doit -- certainement --
correspondre au nombre de point dans le chromatogramme. Dans ce fichier, il y a
une ligne par position (/ie/ par base) gardée dans la séquence trimmée. On
appelle donc cette position /SCF.position/.

Cette position permet de joindre le fichier =phd= avec le fichier =snp= (la
sortie de polysnp), /via/ le champ /SCF.position/, puis avec le fichier =poly=,
le fichier qui recense les bases polymorphes (sortie de phred), /via/ le champ
/position/. 

Script préliminaire d'analyse du fichier pW85 seulement. 
#+BEGIN_SRC R
  setwd("./data/snp-calling")

  library(dplyr)
  library(ggplot2)
  library(viridis)
  library(readr)

  phd$SCF.position <- as.integer(rownames(phd))
  ## phd

  left_join(phd, poly) %>%
    left_join(snp, by = "SCF.position") ->
    snp

  snp %>%
    select(
      base = toupper(baseCall),
      qual = quality,
      rpos = position,
      qpos = SCF.position,
      air1 = area,
      rel1 = relativeAreaCalledPeak,
      ubas = uncalledBase,
      upos = positionUncalledBase,
      air2 = areaUncalledBase,
      rel2 = relativeAreaUncalledBase,
      A    = A,
      C    = C,
      G    = G,
      T    = T,
      type = type.x,
      file = file,
      anls = analysis,
      datm = datum,
      comt = comments,
      recv = A.base,
      donn = B.base,
      fcal = first.call,
      fara = first.area,
      scal = second.call,
      sara = second.area,
      rat1 = uncorrected.proportion.A,
      rat2 = uncorrected.proportion.B,
      snp = type.y
    ) ->
  snp
#+END_SRC

On s'est rendu compte qu'il n'était pas possible de joindre le fichier polysnp
obtenu avec le fichier phd sur la base de la position dans la séquence, puisque
polysnp ne prend pas en compte la séquence trimmée, alors que le fichier POLY le
prend en compte.

Il faut donc changer l'origine du fichier polySNP, pour que la position sur la
séquence reflète la position sur la séquence non trimmée, pas sur la séquence
trimmée. 

On pense faire ça en utilisant la sortie de phred, qui permet de connaître la
séquence trimmée. On peut alors calculer sa longueur, et l'ajouter à la colonne
dans polySNP. 

#+BEGIN_SRC R
  setwd("./data/snp-calling")

  library(dplyr)
  library(ggplot2)
  library(viridis)
  library(readr)

  col_adn <- function() col_factor(c("a", "t", "c", "g", "n"))
  col_ADN <- function() col_factor(c("A", "T", "C", "G", "N"))

  # 10'' environ
  data <- readr::read_csv(
    "huge-strong.csv",
    col_types = cols(
      baseCall     = col_adn(),
      calledBase   = col_ADN(),
      uncalledBase = col_ADN(),
      ## areaUncalledBase = col_double(na = c("-1")),
      mutant       = col_factor(c("strong", "weak")),
      A.base       = col_ADN(),
      B.base       = col_ADN(),
      first.call   = col_ADN(),
      second.call  = col_ADN(),
      second.area  = col_double(),
      snp_         = col_factor(c("snp"))),
    na = c("-", "", "-1")) %>%
    select(
      plas = plasmide, # nom de la construction
      mutt = mutant, # weak ou strong
      base = baseCall, # 
      ubas = uncalledBase, # base non appelée
      fcal = first.call,
      scal = second.call,
      qpos = SCF.position, # position sur la séquence
      recv = A.base,
      donn = B.base,
      air1 = area, # aire du pic primaire
      air2 = areaUncalledBase,
      rel1 = relativeAreaCalledPeak, # 
      rel2 = relativeAreaUncalledBase,
      refp = reference.position, 
      ## upos = positionUncalledBase, # position de la base non appelée sur le spectrogramme 
      ## rel2 = parse_double(relativeAreaUncalledBase, na = c("-1", NA)),
      ## file = file,
      ## anls = analysis,
      ## datm = datum,
      ## fara = first.area,
      ## sara = second.area,
      rat1 = uncorrected.proportion.A,
      ## rat2 = uncorrected.proportion.B,
      snp  = snp_,
      qual = quality,
      comt = comments,
      spos = position, # position sur le spectrogramme
      A    = A,
      C    = C,
      G    = G,
      T    = T
    ) %>%
    mutate(base = toupper(base),
           plas = gsub("-1073.ab1", "", plas),
           rel2 = parse_double(.$rel2, na = c("-1")),
           air2 = parse_double(.$air2, na = c("-1")))

  ## réaffecte les niveaux de facteur. 
  ##
  ## +---------+-------------------------------------------------------+
  ## | facteur | commentaire                                           |
  ## |---------+-------------------------------------------------------|
  ## | D       | WARNING: bases could not be matched                   |
  ## | C       | WARNING: multiple peak span, data are not trustworthy |
  ## | B       | WARNING: primary peak does not match the reference    |
  ## | A       | processed normally                                    |
  ## +---------+-------------------------------------------------------+

  ## il n'y a pas dans les données de facteur C. d'où les trois niveaux de
  ## facteur. sensible aux variations de paramètre polySNP à mon avis. à
  ## surveiller.
  data$comt <- factor(data$comt)
  ## length(levels(data$comt))
  data$comt <- plyr::mapvalues(data$comt,
                               from = levels(data$comt),
                               to = c("D", "B", "A"))

  ## glimpse(data)

  data %>%
    filter(!is.na(fcal)) %>%
    rowwise() %>%
    filter(fcal != base) 

  data %>%
    filter(snp== "snp") %>%
    rowwise() %>%
    filter(as.character(scal) == as.character(ubas))

  # TODO trouver un moyen de dire à readr::read_csv() le type des colonnes. 

  data %>%
    group_by(comt) %>%
    summarise(count = n()) 

  data %>%

  parse_double(data$rel2, na = c("-1")) %>% head

  data %>%
    filter(ubas != "N") %>%
    group_by(snp) %>%
    summarise(count = n()) 


  theme_set(
    theme_minimal(base_size = 6, base_family = "Courier") +
    theme(panel.grid.major.y = element_line(colour = "gray", linetype = "dotted"),
          panel.grid.minor.y = element_line(colour = "gray", linetype = "dotted"),
          panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank())
  )


  data %>%
    filter(ubas != "N") %>%
    ggplot(data = .,
           aes(x = qpos, y = plas, fill = ubas, label = ubas)) +
    geom_tile() 
    ## geom_text() 


  data %>%
    filter(!is.na(snp)) %>%
    rowwise() %>%
    ## filter(ubas != "N") %>%
    filter(scal != ubas) %>%
    print()
    {
      .$qpos
    } ->
    snppos

  data %>%
    filter(!is.na(snp)) %>%
    rowwise() %>%
    filter(fcal != base) %>%
    print()
    group_by(mutt) %>%
    summarise(count = n()) 
#+END_SRC
* Makefile 
#+BEGIN_SRC makefile :tangle ./Makefile
## analyses hétérozygotes
analysis/snp_distribution.pdf: scripts/polysnip.R
	Rscript $<

analysis/switch_distrib.pdf: scripts/polysnip.R
	Rscript $<

analysis/mutant-count.pdf: scripts/polysnip.R
	Rscript $<

analysis/mutant-second.pdf: scripts/polysnip.R
	Rscript $<

scripts/polysnip.R: scripts/polysniper.sh				\
	scripts/polysniper-strong.sh									\
	scripts/polysniper-weak.sh
	bash $<

scripts/polysniper.sh: scripts/extract_raw_data.sh
	bash $<



## analyses des variants
analysis/qualite_distrib.pdf: scripts/variant_analysis.R
	Rscript $<

analysis/bgc_en_action.pdf: scripts/variant_analysis.R
	Rscript $<

analysis/candidats_heterozygotes.pdf: scripts/variant_analysis.R
	Rscript $<

analysis/inside_conv.tex: scripts/variant_analysis.R
	Rscript $<

analysis/mutant_snp_distribution.pdf: scripts/variant_analysis.R
	Rscript $<

analysis/per_base_quality_fastqc_trimmed.png: scripts/

analysis/per_base_quality_fastqc_untrimmed.png: scripts/

#+END_SRC

* Commentaires
** [2015-11-09 Mon]
Pas de données dans le fichier [[./data/fasta/pS6-1073.fas]], mais pourtant le
fichier [[./data/spectrograms/pS6-1073.ab1]] en contient. On repart des .ab1 avec un
script [[./scripts/ab1_parser.py]], qui convertit les .ab1 en fasta et fastq. 

Le fichier [[./data/fasta/pS6-1073.fst]] est toujours aussi mauvais. Erreurs de
séquençage ? À exclure des analyses. 

Le fichier [[./data/fasta/pS9-1073.fst]] a un indel en position 343-342 et en
position 397. Au vu du spectrogramme [[./data/spectrograms/pS9-1073.ab1]], c'est une
erreur de séquençage. Globalement, qualité du séquençage pas très bonne. À
exclure des analyses.
** [2015-11-16 Mon]
La semaine dernière, le script [[./scripts/ab1_parser.py]] convertissait tous les
spectrograms de =ab1= vers =fastq=. Combiné en 1 fichier, =all.fastq=, on a
utilisé /fastqc/ pour avoir une idée de la qualité. Le résultat dans
[[./analysis/all_fastqc.html]]. Il a été convenu arbitrairement avec Vincent que les
bases d'une qualité < 28 seraient exclues de l'analyse. Aujourd'hui, le script
[[./scripts/ab1_parser.py]] va être modifié en conséquence. Voir les anciennes
versions via /git/ éventuellement.

J'écris également aujourd'hui le script [[./scripts/trim_low_quality.py]], qui
enlève les 30 premières et dernières séquences, et qui empêche les séquences de
trop mauvaise qualité d'être utilisées dans l'analyse. 

Finalement, inutile de réinventer la roue. =Fastx_toolkit= devrait normalement
faire ça très bien, mais ça ne fonctionne pas, pour des raisons que je ne
m'explique pas. Cependant, je suis tombé sur l'utilitaire =BBmap=, qui contient
entre autre, =bbduk=. [[~/.bin/bbmap/bbduk.sh][Voir le fichier source ici]], la page de téléchargement [[http://sourceforge.net/projects/bbmap/?source=typ_redirect][là]],
et pour des commentaires sur l'utilisation [[http://seqanswers.com/forums/showthread.php?t=58221][Voir là]], et [[http://seqanswers.com/forums/showthread.php?t=42776][là]].

** [2015-11-17 Tue]
Je supprime donc le script =low_quality_trim.py=. J'utilise le script
=low_quality_trim.sh=. 

En résultat, comparer [[./analysis/trimmed_fastqc.html]] et
[[./analysis/untrimmed_fastqc.html]]. On n'a plus que 179 séquences au lieu de 192,
mais ça vaut le coup, la qualité est largement supérieure. 

Je veux maintenant déterminer les SNPs. Il faut donc que j'aligne les séquences
obtenues avec la séquence de référence [[./data/refseq.fasta]]. GATC utilise le
software =SSAHA2= (voir [[http://www.sanger.ac.uk/science/tools/ssaha2-0][là]]) mais à priori il n'est plus utilisable. Le site
recommande d'utiliser =SMALT=, (voir la page de téléchargement [[http://sourceforge.net/projects/smalt/?source=typ_redirect][là]], le manuel [[ftp://ftp.sanger.ac.uk/pub/resources/software/smalt/smalt-manual-0.7.4.pdf][là]]
et la page du software [[http://www.sanger.ac.uk/science/tools/smalt-0][là]]. 

En fait, je l'ai juste installé comme ça :

#+BEGIN_SRC sh
brew update
brew tap homebrew/homebrew-science
brew install smalt
#+END_SRC

Finalement, c'est encore un autre workflow que je veux adopter. On repart sur
=ssaha2= et =ssaha2SNP=, la page de téléchargement étant
[[ftp://ftp.sanger.ac.uk/pub/resources/software/ssaha2/]].  
** [2015-11-18 Wed]
Il faut clarifier les étapes permettant d'aligner et de déterminer les SNP. Ce
qui est fait dans le script [[./scripts/variantCallerSsaha2.sh]]. 
** [2015-11-20 Fri]
Le rapport était basé sur une version de ma fonction =mutant_caller= dans le
script R [[./scripts/variant_analysis.R]] qui était fausse. Très fausse. Beaucoup de
boulot à corriger. 

** [2015-11-28 Sat]
La photo suivante montre le spectrogramme d'une position appelée N dans les
alignements. Pour moi c'est la marque de l'hétérogénéité dans la colonie. Les
uns réparent en G, les autres en A ou T.

On peut clairement voir que la base appelée est le T, mais qu'il persiste un G
dans à cette position. 30 bases plus loin, idem, un T est appelée mais un C persiste. 

 [[./analysis/weak_spectro.png]] 

** [2015-12-03 Thu]
J'ai cherché à extraire les données trace par trace, mais à priori il n'y a pas
d'OSS qui permette de faire ça. On va donc utiliser la qualité comme proxy du
polymorphisme. Ça implique de baisser le seuil d'exigence quant aux bases qu'on
décide de renommer =N=. Donc modification du script 
* Dossiers et fichiers
#+BEGIN_SRC sh :results verbatim 
tree ./ -L 2
#+END_SRC


| dossier  | fichier ou dossier                      | description                                                                 |
|----------+-----------------------------------------+-----------------------------------------------------------------------------|
| analysis |                                         |                                                                             |
|          | -- plots                                | dossier contenant les différents plots générés par plots-bcftools.          |
|          | -- snp_distribution.pdf                 | la distribution des SNP sans tenir compte de la provenance des mutants      |
|          | -- snp_resume.pdf                       | les trois plots sur la même feuille                                         |
|          | -- substitution_distribution.pdf        | la distribution des substitutions.                                          |
|          | -- trimmed_fastqc.html                  | le contrôle de la qualité des séquences trimmées via fastqc                 |
|          | -- untrimmed_fastqc.html                | le contrôle de la qualité des séquences non-trimmées via fastqc             |
|          | -- vincent_plot.pdf                     | le graphe de vincent le jour de la réception des données.                   |
|          | -- Analysis_Summary-Sanger_Pipeline.pdf | description du fichier d'analyse GATK                                       |
|----------+-----------------------------------------+-----------------------------------------------------------------------------|
| data     |                                         |                                                                             |
|          | -- 1369607.INDEL.csv                    | le fichier envoyé par GATK                                                  |
|          | -- 1369607.SNP.csv                      | le fichier envoyé par GATK                                                  |
|          | -- 1369628.INDEL.csv                    | le fichier envoyé par GATK                                                  |
|          | -- 1369628.SNP.csv                      | le fichier envoyé par GATK                                                  |
|          | -- all.fasta                            | toutes les séquences                                                        |
|          | -- fasta                                | dossier contenant les séquences une à une                                   |
|          | -- fastq                                | idem en fastq                                                               |
|          | -- id_table.dat                         | une table contenant les nom de séquence, le mutant, et la qualité du mutant |
|          | -- raw_seq_nvbr                         | le dossier contenant les données brutes. NEPASTOUCHER                       |
|          | -- reference.fasta                      | la séquence de référence                                                    |
|          | -- refseq.fasta                         | idem                                                                        |
|          | -- refseq_reverse.fasta                 | la séquence de référence reversed.                                          |
|          | -- seq                                  | le dossier contentant les séquneces                                         |
|          | -- spectrograms                         | le dossier contentant les .ab1 files                                        |
|          | -- tmp                                  | un dossier de travail                                                       |
|          | -- trimmed.fasta                        | les séquences trimmées                                                      |
|          | -- trimmed.fastq                        | idem                                                                        |
|          | -- untrimmed.fastq                      | les séquences non trimmées                                                  |
|          | -- variantCalling                       | le dossier de travail pour l'analyse des variants                           |
|----------+-----------------------------------------+-----------------------------------------------------------------------------|
| scripts  |                                         |                                                                             |
|          | -- ab1_parser.py                        | convertit l'ensemble des fichiers .ab1 en fastq                             |
|          | -- ab1_to_fastq                         | idem, utilitaire pipeable                                                   |
|          | -- exploratory_analysis.R               | premières analyses dans R                                                   |
|          | -- extract_raw_data.sh                  | met en place la structure de données                                        |
|          | -- make_id_table.py                     | crée le fichier ../data/id_table.dat                                        |
|          | -- quality_check                        | analyse la qualité via fastqc                                               |
|          | -- trim_low_quality.sh                  | trimme les séquences via bbduk                                              |
|          | -- variantCallerBwa.sh                  | un premier essai d'alignement et de snp calling via samtools et bcftools    |
|          | -- variantCallerSsaha2.sh               | l'alignement avec ssaha2SNP                                                 |
|          | -- variant_analysis.R                   | l'analyse des variants et les graphes qui vont avec                         |


* configuration                                                                 :noexport:
#+TODO: TODO FIX! | DONE
# #+OPTIONS: num:t H:4
#+OPTIONS: toc:3
#+BABEL: :session *R* :cache yes :results output graphics :exports both :tangle yes

