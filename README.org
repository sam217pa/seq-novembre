#+begin_src emacs-lisp :results none :export none
  (org-babel-tangle-file "README.org")
#+end_src

Le dossier contient les données du séquençage des deux plaques envoyées à la
suite des manips d'Anne-Laure. 

* Structure
#+BEGIN_SRC sh :results verbatim 
tree ./ -L 2
#+END_SRC


| dossier  | fichier ou dossier                      | description                                                                 |
|----------+-----------------------------------------+-----------------------------------------------------------------------------|
| analysis |                                         |                                                                             |
|          | -- plots                                | dossier contenant les différents plots générés par plots-bcftools.          |
|          | -- snp_distribution.pdf                 | la distribution des SNP sans tenir compte de la provenance des mutants      |
|          | -- snp_resume.pdf                       | les trois plots sur la même feuille                                         |
|          | -- substitution_distribution.pdf        | la distribution des substitutions.                                          |
|          | -- trimmed_fastqc.html                  | le contrôle de la qualité des séquences trimmées via fastqc                 |
|          | -- untrimmed_fastqc.html                | le contrôle de la qualité des séquences non-trimmées via fastqc             |
|          | -- vincent_plot.pdf                     | le graphe de vincent le jour de la réception des données.                   |
|----------+-----------------------------------------+-----------------------------------------------------------------------------|
| data     |                                         |                                                                             |
|          | -- 1369607.INDEL.csv                    | le fichier envoyé par GATK                                                  |
|          | -- 1369607.SNP.csv                      | le fichier envoyé par GATK                                                  |
|          | -- 1369628.INDEL.csv                    | le fichier envoyé par GATK                                                  |
|          | -- 1369628.SNP.csv                      | le fichier envoyé par GATK                                                  |
|          | -- Analysis_Summary-Sanger_Pipeline.pdf | description du fichier d'analyse GATK                                       |
|          | -- all.fasta                            | toutes les séquences                                                        |
|          | -- fasta                                | dossier contenant les séquences une à une                                   |
|          | -- fastq                                | idem en fastq                                                               |
|          | -- id_table.dat                         | une table contenant les nom de séquence, le mutant, et la qualité du mutant |
|          | -- raw_seq_nvbr                         | le dossier contenant les données brutes. NEPASTOUCHER                       |
|          | -- reference.fasta                      | la séquence de référence                                                    |
|          | -- refseq.fasta                         | idem                                                                        |
|          | -- refseq_reverse.fasta                 | la séquence de référence reversed.                                          |
|          | -- seq                                  | le dossier contentant les séquneces                                         |
|          | -- spectrograms                         | le dossier contentant les .ab1 files                                        |
|          | -- tmp                                  | un dossier de travail                                                       |
|          | -- trimmed.fasta                        | les séquences trimmées                                                      |
|          | -- trimmed.fastq                        | idem                                                                        |
|          | -- untrimmed.fastq                      | les séquences non trimmées                                                  |
|          | -- variantCalling                       | le dossier de travail pour l'analyse des variants                           |
|----------+-----------------------------------------+-----------------------------------------------------------------------------|
| scripts  |                                         |                                                                             |
|          | -- ab1_parser.py                        | convertit l'ensemble des fichiers .ab1 en fastq                             |
|          | -- ab1_to_fastq                         | idem, utilitaire pipeable                                                   |
|          | -- exploratory_analysis.R               | premières analyses dans R                                                   |
|          | -- extract_raw_data.sh                  | met en place la structure de données                                        |
|          | -- make_id_table.py                     | crée le fichier ../data/id_table.dat                                        |
|          | -- quality_check                        | analyse la qualité via fastqc                                               |
|          | -- trim_low_quality.sh                  | trimme les séquences via bbduk                                              |
|          | -- variantCallerBwa.sh                  | un premier essai d'alignement et de snp calling via samtools et bcftools    |
|          | -- variantCallerSsaha2.sh               | l'alignement avec ssaha2SNP                                                 |
|          | -- variant_analysis.R                   | l'analyse des variants et les graphes qui vont avec                         |

* Commentaires
** [2015-11-09 Mon]
Pas de données dans le fichier [[./data/fasta/pS6-1073.fas]], mais pourtant le
fichier [[./data/spectrograms/pS6-1073.ab1]] en contient. On repart des .ab1 avec un
script [[./scripts/ab1_parser.py]], qui convertit les .ab1 en fasta et fastq. 

Le fichier [[./data/fasta/pS6-1073.fst]] est toujours aussi mauvais. Erreurs de
séquençage ? À exclure des analyses. 

Le fichier [[./data/fasta/pS9-1073.fst]] a un indel en position 343-342 et en
position 397. Au vu du spectrogramme [[./data/spectrograms/pS9-1073.ab1]], c'est une
erreur de séquençage. Globalement, qualité du séquençage pas très bonne. À
exclure des analyses.
** [2015-11-16 Mon]
La semaine dernière, le script [[./scripts/ab1_parser.py]] convertissait tous les
spectrograms de =ab1= vers =fastq=. Combiné en 1 fichier, =all.fastq=, on a
utilisé /fastqc/ pour avoir une idée de la qualité. Le résultat dans
[[./analysis/all_fastqc.html]]. Il a été convenu arbitrairement avec Vincent que les bases d'une
qualité < 28 seraient exclues de l'analyse. Aujourd'hui, le script
[[./scripts/ab1_parser.py]] va être modifié en conséquence. Voir les anciennes
versions via /git/ éventuellement.

J'écris également aujourd'hui le script [[./scripts/trim_low_quality.py]], qui
enlève les 30 premières et dernières séquences, et qui empêche les séquences de
trop mauvaise qualité d'être utilisées dans l'analyse. 

Finalement, inutile de réinventer la roue. =Fastx_toolkit= devrait normalement
faire ça très bien, mais ça ne fonctionne pas, pour des raisons que je ne
m'explique pas. Cependant, je suis tombé sur l'utilitaire =BBmap=, qui contient
entre autre, =bbduk=. [[~/.bin/bbmap/bbduk.sh][Voir le fichier source ici]], la page de téléchargement [[http://sourceforge.net/projects/bbmap/?source=typ_redirect][là]],
et pour des commentaires sur l'utilisation [[http://seqanswers.com/forums/showthread.php?t=58221][Voir là]], et [[http://seqanswers.com/forums/showthread.php?t=42776][là]].

** [2015-11-17 Tue]
Je supprime donc le script =low_quality_trim.py=. J'utilise le script
=low_quality_trim.sh=. 

En résultat, comparer [[./analysis/trimmed_fastqc.html]] et
[[./analysis/untrimmed_fastqc.html]]. On n'a plus que 179 séquences au lieu de 192,
mais ça vaut le coup, la qualité est largement supérieure. 

Je veux maintenant déterminer les SNPs. Il faut donc que j'aligne les séquences
obtenues avec la séquence de référence [[./data/refseq.fasta]]. GATC utilise le
software =SSAHA2= (voir [[http://www.sanger.ac.uk/science/tools/ssaha2-0][là]]) mais à priori il n'est plus utilisable. Le site
recommande d'utiliser =SMALT=, (voir la page de téléchargement [[http://sourceforge.net/projects/smalt/?source=typ_redirect][là]], le manuel [[ftp://ftp.sanger.ac.uk/pub/resources/software/smalt/smalt-manual-0.7.4.pdf][là]]
et la page du software [[http://www.sanger.ac.uk/science/tools/smalt-0][là]]. 

En fait, je l'ai juste installé comme ça :

#+BEGIN_SRC sh
brew update
brew tap homebrew/homebrew-science
brew install smalt
#+END_SRC

Finalement, c'est encore un autre workflow que je veux adopter. On repart sur
=ssaha2= et =ssaha2SNP=, la page de téléchargement étant
[[ftp://ftp.sanger.ac.uk/pub/resources/software/ssaha2/]].  
** [2015-11-18 Wed]
Il faut clarifier les étapes permettant d'aligner et de déterminer les SNP. Ce
qui est fait dans le script [[./scripts/variantCallerSsaha2.sh]]. 

** [2015-11-20 Fri]
Le rapport était basé sur une version de ma fonction =mutant_caller= dans le
script R [[./scripts/variant_analysis.R]] qui était fausse. Très fausse. Beaucoup de
boulot à corriger. 

* Analyses 
Contient les résultats des analyses. Graphes ou données transformées. 
* Scripts 

Contient les différents scripts nécessaires pour aboutir aux contenus
d'~analysis~. 

** Extraction des données brutes
Pour extraire les données du fichier brut .zip à la structure de données.

#+BEGIN_SRC sh :tangle ./scripts/extract_raw_data.sh 
  #!/bin/bash 

  cd ~/stage/seq_novembre/
  # Le script qui extrait les données depuis les fichiers zip bruts et qui met en
  # place la structure de fichier.

  cd ./data
  ## extraction des données brutes
  unzip raw_seq_nvbr/1369607.zip
  unzip raw_seq_nvbr/1369628.zip

  ## crée les dossiers
  mkdir fasta seq spectrograms csv
  ## déplace tout les fichiers dans des dossiers adaptés 
  find . -name "*.fas" -exec mv -i {} -t ./fasta/ \;
  find . -name "*.ab1" -exec mv -i {} -t ./spectrograms/ \;
  find . -name "*.seq" -exec mv -i {} -t ./seq/ \;
  find . -name "*.csv" -exec mv -i {} -t ./csv/ \;

  # déplace le contenu du dossier inutile dans le présent dossier
  mv 1369628/* ./
  rm -r 1369628 # supprime le dossier
  # déplace le fichier pdf dans le dossier adapté
  mv *.pdf ../analysis
#+END_SRC

Les spectrogrammes contiennent l'info de la sequence_id et du nom. 
On construit une table avec la qualité du mutant en troisième colonne. 

#+BEGIN_SRC python :tangle ./scripts/make_id_table.py
  from Bio import SeqIO
  import glob

  def strong_or_weak(record):
      """
      Determine si le mutant est strong ou weak
      """
      if 'S' in record:
          return 'strong'
      else:
          return 'weak'

  # en-tete de colonne
  print "id name mutant"

  # pour chaque fichier ab1
  for file in glob.glob("../data/spectrograms/*.ab1"):
      with open(file, "rb") as spectro:
          for record in SeqIO.parse(spectro, "abi"):
              # associer l'id avec le nom et le type de mutant
              print record.id + " " + record.name + \
                  " " + strong_or_weak(record.name)
#+END_SRC

On crée la table en question via :
#+BEGIN_SRC sh
  cd ~/stage/seq_novembre/scripts
  python make_id_table.py > ../data/id_table.dat
#+END_SRC

** Des spectrogrammes aux données fastq non-trimmées
*** prérequis

#+BEGIN_SRC sh
brew install emboss
#+END_SRC

*** via seqret

#+BEGIN_SRC sh :tangle ./scripts/ab1_to_fastq.sh
  cd ~/stage/seq_novembre/scripts

  touch untrimmed.fastq
  for file in ../data/spectrograms/*.ab1
  do
      seqret \
          -sformat abi \
          -osformat fastq \
          -auto \
          -stdout \
          -sequence $file \
          >> ../data/untrimmed.fastq
  done

  fastq_to_fasta -i ../data/untrimmed.fastq -o ../data/untrimmed.fasta
#+END_SRC

** Des données non-trimmées aux données trimmées et filtrées
Un script qui convertit le fichier [[./data/untrimmed.fastq]] en fichier [[./data/trimmed.fastq]]

#+BEGIN_SRC sh :tangle ./scripts/trim_low_quality.sh
  #!/usr/local/bin/bash

  #' -qtrim=rl : quality trim right and left 
  #' -trimq=28 : trim if quality < 28 (sanger encoding, illumina 1.9)
  #' -minlen=620 : keep only seq with length > 620, after trimming.
  #' -Xmx1g : tells bbduk / java to use 1G of RAM

  if [[ -f ../data/untrimmed.fastq && ! -f ../data/trim.fastq ]]
  then # si les fichiers n'existent pas.
      ~/.bin/bbmap/bbduk.sh -Xmx1g \
                            -in=../data/untrimmed.fastq \
                            -out=../data/trim.fastq \
                            -qtrim=rl \
                            -trimq=28 \
                            -minlen=620

      seqtk seq -q28 -nN ../data/trim.fastq > ../data/trimmed.fastq
      fastq_to_fasta -i ../data/trimmed.fastq -o ../data/trimmed.fasta
      rm ../data/trim.fastq
  else
      printf "Le fichier untrimmed.fastq n'existe pas, ou le fichier trimmed.fastq existe déjà."
  fi
#+END_SRC

** Analyse de la qualité des séquences
Le script utilisé pour analyser les données de qualité via /fastqc/. 

#+BEGIN_SRC sh :tangle scripts/quality_check.sh
  #!/usr/local/bin/bash
  cd ~/stage/seq_novembre/scripts

  # quand dans le dossier ./scripts
  cd ../data/

  if [ -f untrimmed.fastq ] && [ -f trimmed.fastq ] ; then
      mkdir tmp
      # analyse les données et output dans tmp
      fastqc untrimmed.fastq -o ./tmp
      fastqc trimmed.fastq   -o ./tmp
      # unzip resulting files
      unzip -qq tmp/untrimmed_fastqc.zip -d tmp
      unzip -qq tmp/trimmed_fastqc.zip -d tmp
      # extract main results
      mv tmp/untrimmed_fastqc/Images/per_base_quality.png \
         ../analysis/per_base_quality_fastqc_untrimmed.png
      mv tmp/trimmed_fastqc/Images/per_base_quality.png \
         ../analysis/per_base_quality_fastqc_trimmed.png
      # copy html into analysis
      mv tmp/*.html ../analysis/
      # delete tmp files
      rm -r tmp # remove temporary files

  else
      printf "Les fichiers untrimmed.fastq et trimmed.fastq n'existent pas."
  fi
#+END_SRC 

** Détermination des SNP

#+BEGIN_SRC sh :tangle ./scripts/variantCallerSsaha2.sh
  #!/bin/bash
  # variant calling using ssaha2 and ssaha2SNP

  cd ~/stage/seq_novembre/data
  ## prend le reverse complement de la séquence de référence
  fastx_reverse_complement -i reference.fasta -o reference_reverse.fasta

  mkdir variantCalling
  cd variantCalling

  ## place les séquences nécessaires pour l'analyse dans le dossier. 
  ln -s ../trimmed.fastq .
  ln -s ../reference_reverse.fasta ./reference_reverse.fasta

  ## alignement à la séquence de référence
  #' -output psl :             format de sortie psl
  #' reference_reverse.fasta : séquence de référence
  #' trimmed.fastq :           séquence à aligner
  #' output.psl :              fichier de sortie
  ~/.bin/ssahaSNP/ssaha2 -output psl reference_reverse.fasta trimmed.fastq > output.psl

  ## polymorphism detection tool
  ~/.bin/ssahaSNP/ssahaSNP reference_reverse.fasta trimmed.fastq > SNP.txt

  ## computer readable format conversion
  # egrep trouve les lignes où sont indiquées les données concernant les SNP
  # awk extrait les champs en question dans un fichier SNP.dat
  egrep ssaha:SNP SNP.txt | \
      awk '{print $1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14,$15}' > SNP.dat

  ## column annotation based on
  ## ftp://ftp.sanger.ac.uk/pub/resources/software/ssahasnp/readme,
  ## part (6) some further information
  # la première ligne du fichier .dat, afin d'être lu dans R
  echo " match subject_name index_of_subject read_name s_base q_base s_qual q_qual offset_on_subject offset_on_read length_of_snp start_match_of_read end_match_of_read match_direction length_of_subject " > head.dat
  # into final document
  cat head.dat SNP.dat > snp_calling.dat
#+END_SRC

** Analyse des variants
*** Lecture des données et nettoyage
Le fichier [[~/stage/seq_novembre/data/variantCalling/snp_calling.dat]] contient les
données d'intérêt. Il ne contient ni le nom du transformant, ni son type (Weak
ou Strong). Les données sont récupérées dans le fichier [[data/id_table.dat]]. Les
deux tables sont associés via un /inner_join/. 

#+BEGIN_SRC R :tangle ./scripts/variant_analysis.R
  setwd("~/stage/seq_novembre/data/variantCalling")

  library(dplyr)

  ## read the data
  snp <- tbl_df(read.table("snp_calling.dat", head = TRUE))
  ## enlève les colonnes inutiles
  snp %>%
      select( -match, -subject_name, -index_of_subject, -length_of_subject,
             -match_direction) ->
      snp
  ## lit les métadonnées de séquence
  id_table <- tbl_df(read.table("../id_table.dat", head = TRUE))

  ## fait correspondre le read_name avec le nom du clone et le type de mutant W ou S
  snp_data <- inner_join(x = snp, y = id_table, by = c("read_name" = "id"))
#+END_SRC

*** Détermine la qualité des SNP
Pour déterminer si le SNP est de type /weak/ ou /strong/, j'utilise la fonction
=mutant_caller=. Si la référence est A ou T, soit le transformant est C ou G, et
la substitution est /WS/ ; soit le transformant est A ou T, et la mutation est
/WW/. Si la référence est C ou G, soit le transformant est A ou T, et la
substitution est /SW/ ; soit le transformant est G ou C, la substitution et est
/SS/.

#+BEGIN_SRC R :tangle ./scripts/variant_analysis.R
  #' une fonction pour déterminer si la substitution est strong ou weak. On peut
  #' avoir des substitutions weak chez les strongs
  #' @param subject la base sur la séquence de référence
  #' @param query la base sur le read.
  mutant_caller <- function(subject, query)
  {
      if (subject == 'A' || subject == 'T') {
          if (query == 'C' || query == 'G' ) {
              'WS'
          } else {
              'WW'
          }
      } else if (subject == 'C' || subject == 'G') {
          if (query == 'A' || query == 'T') {
              'SW'
          } else {
              'SS'
          }
      }
  }

  ## on applique la fonction rowwise, ie ligne par ligne, via `mutate`, puis on
  ## dégroupe.
  snp_data %>%
      rowwise() %>%
      mutate(mutation_type = mutant_caller(s_base, q_base)) %>%
      ungroup() ->
      snp_data
  ## conversion en facteur
  snp_data$mutation_type = factor(snp_data$mutation_type)
#+END_SRC

*** Graphiques globaux
Des graphiques de distribution globale des SNP sont fait ici. 

#+BEGIN_SRC R :tangle ./scripts/variant_analysis.R
  library(ggplot2)
  library(ggthemes)

  mytheme <- theme(panel.ontop = TRUE,
                   axis.text = element_text(size = 8, colour = "gray"),
                   panel.grid.major.x = element_blank(),
                   panel.grid.minor.x = element_blank(),
                   panel.grid.minor.y = element_blank(),
                   panel.grid.major.y = element_line(colour = "white", size = 1)) 

  ##==============================================================================
  ## PLOT DISTRIBUTIONS
  ##==============================================================================
  snp_plot <- ggplot(data = snp_data, aes(offset_on_subject)) +
      geom_density(aes(fill = mutant), alpha = 0.2) +
      geom_histogram(aes(fill = mutant),
                     binwidth = 10, position = "dodge") +
      theme_minimal(base_family = "Courier") +
      scale_x_continuous(breaks = seq(1, 734, 30)) +
      scale_fill_brewer(palette = "Set2", name = "Type de gène\nsynthétique") +
      xlab("Distribution des SNP sur le gene sauvage") +
      ylab("") +
      theme(panel.ontop = TRUE,
            legend.position = c(0.8, 0.8),
            axis.text = element_text(size = 8, colour = "gray"),
            panel.grid.major.x = element_blank(),
            panel.grid.minor.x = element_blank(),
            panel.grid.minor.y = element_blank(),
            panel.grid.major.y = element_line(colour = "white", size = 1)) 

  ## distribution des SNP
  ## facétée par type de mutant, couleur = type de mutation
  mutation_plot <- ggplot(data = snp_data, aes(offset_on_subject)) +
      geom_histogram(aes(fill = mutation_type), binwidth = 10, position = "dodge") +
      facet_grid(~mutant, labeller = label_both) +
      theme_minimal(base_family = "Courier") +
      scale_x_continuous(breaks = seq(1, 734, 60)) +
      scale_fill_brewer(palette = "Set2",
                        name = "Type de mutation",
                        labels = c("AT -> GC", "GC -> AT")) +
      xlab("Distribution des SNP sur le gene sauvage") +
      ylab("") +
      theme(panel.ontop = TRUE,
            legend.position = c(0.4, 0.8),
            axis.text = element_text(size = 8, colour = "gray"),
            panel.grid.major.x = element_blank(),
            panel.grid.minor.x = element_blank(),
            panel.grid.minor.y = element_blank(),
            panel.grid.major.y = element_line(colour = "white", size = 1)) 

  ##==============================================================================
  ## SAVE PLOTS
  ##==============================================================================
  save_to_a5 <- function(output_file, plot)
  {
      pdf(file = output_file, height = 5.8, width = 8.3)
      print(plot)
      dev.off()
  }

  save_to_a3 <- function(output_file, plot)
  {
                                          # a3 dimensions : 11.69in x 16.53in
      pdf(file = output_file, height = 11.69, width = 16.53)
      print(plot)
      dev.off()
  }

  save_to_a5(output_file = "../../analysis/substitution_distribution.pdf",
             plot = mutation_plot)
  save_to_a5(output_file = "../../analysis/snp_distribution.pdf",
             plot = snp_plot)
  save_to_a5(output_file = "../../analysis/muttype_plot.pdf",
             plot = muttype_plot)

#+END_SRC

*** Positions terminales de switch
On veut ici analyser les positions terminales de SNP. C'est à dire à quel
endroit on bascule à nouveau sur le génotype sauvage. 

#+BEGIN_SRC R :tangle ./scripts/variant_analysis.R
  ##==============================================================================
  ## SWITCH INITIAL
  ##==============================================================================

  ## en tenant compte du type de mutant
  snp_data %>%
      group_by(name, mutant) %>%
      summarise(switch_pos = max(offset_on_subject)) ->
      switch_data_mutant

  switch_pos_by_mutant <- ggplot(switch_data_mutant, aes(switch_pos)) +
      geom_histogram(aes(fill = mutant),
                     position = "dodge", 
                     binwidth = 10) +
      ## facet_grid(.~mutant) +
      scale_x_continuous(breaks = seq(1, 734, 30)) +
      theme_minimal(base_family = "Courier") +
      scale_fill_brewer(palette = "Set2") +
      xlab("Distribution de la position de switch en fonction du type de mutant") +
      ylab("") +
      theme(legend.position = c(0.7, 0.5)) +
      mytheme

  ## sauvegarde du graphique
  cowplot::ggsave(switch_pos_by_mutant, file = "../../analysis/switch_pos_by_mutant.pdf",
         height = 21, width = 29.7, units = "cm")

#+END_SRC

*** SNP inattendus
Le but est de trouver les SNPs aux positions calibrées qui ne sont pas ceux
attendus. Typiquement ce sont les mutations /strong/ dans la manip Weak, et les
mutations /weak/ dans la manip Strong. Si les mutations en questions sont
répétées sur l'ensemble du clone, alors c'est une contamination. Sinon, ce sont
des données intéressantes. 

#+BEGIN_SRC R :tangle ./scripts/variant_analysis.R
  ##============================================================================== 
  ## OUTLIERS
  ##==============================================================================

  #' Détermine si le SNP en question est un outlier ou non, c'est
  #' à dire une mutation strong chez un mutant weak ou inversement.
  #' @param mutant : le type de mutant
  #' @param mutation_type : le type de substitution
  find_outlier <- function(mutant, mutation_type)
  {
      if (mutant == 'strong' && mutation_type == 'weak') {
          'strong_weak'
      } else if (mutant == 'weak' && mutation_type == 'strong') {
          'weak_strong'
      } else {
          'attendu'
      }
  }

  snp_data %>%
      rowwise() %>%
      mutate(outlier = find_outlier(mutant, mutation_type)) %>%
      ungroup() ->
      outlier_data

  pdf(file = "../../analysis/outliers.pdf", width = 4, height = 2)
  outlier_data %>%
      filter(outlier != "attendu") %>%
      qplot(data = ., offset_on_subject, fill = outlier, binwidth = 10) +
      theme_minimal(base_family = "Courier") +
      xlab("") + ylab("") +
      scale_fill_brewer(palette = "Set2",
                        labels = c("S -> W", "W -> S")) +
      theme(legend.position = c(0.8, 0.7),
            legend.title = element_blank(),
            legend.text = element_text(size = 10)) +
      mytheme 
  dev.off()

  pdf(file = "../../analysis/strong_vs_weak.pdf", width = 4, height = 4)
  snp_data %>%
      ggplot(aes(offset_on_subject, fill = mutation_type)) +
      geom_histogram(binwidth = 10) +
      facet_grid(mutation_type ~ .) +
      xlab("") + ylab("") +
      theme_minimal(base_family = "Courier") +
      scale_fill_brewer(palette = "Set2", guide = FALSE) +
      mytheme
  dev.off()

#+END_SRC
*** Détermination des SNP calibrés

On veut filtrer les positions qui sont bien les SNP calibrés. 

#+BEGIN_SRC R :tangle ./scripts/variant_analysis.R
    snp_data %>% group_by(offset_on_subject) %>%
        summarise(count = n()) %>%
        filter(count > 10) ->
        position_table

    #' détermine si la postion sur la séquence de référence est un SNP artificiel ou
    #' un autre genre de SNP.
    is_a_position <- function(position, table)
    {
        ifelse(position %in% table, 'yes', 'no')
    }

    snp_data %>%
        rowwise() %>%
        mutate(position = is_a_position(offset_on_subject,
                                        position_table$offset_on_subject)) %>%
        ungroup() ->
        snp_data

  ### work in progress
  ## snp_data %>%
  ##     filter(position == "yes") %>%
  ##     qplot(data = ., offset_on_subject, q_qual, geom = "point", color = mutant) +
  ##     theme_minimal() +
  ##     geom_vline(xintercept = snp_data$offset_on_subject, alpha = 0.1)
#+END_SRC

*** Détermination de la position des SNP par rapport à la conversion tract

Écrire une fonction =is_inside_conversion= qui détermine si un SNP est en dehors
ou en dedans de la conversion tract. 

* Script Principal 

#+BEGIN_SRC sh :tangle ./scripts/run_analysis.sh
  cd ~/stage/seq_novembre/scripts

  chmod +x *.sh

  ./extract_raw_data.sh                          # extrait les données des .zip et
                                                 # organise en sous fichiers

  ./ab1_to_fastq.sh                              # extrait les fastq et fasta
                                                 # depuis les .ab1

  ./trim_low_quality.sh                          # supprime les données de faible
                                                 # qualité et transforme les bases
                                                 # de qualité inférieure à 28 en N

  ./quality_check.sh                             # analyse fastqc, crée les
                                                 # graphes en png et sortie des
                                                 # html dans le dossier analysis

  ./variantCallerSsaha2.sh                       # détermine la position des SNP
                                                 # basé sur la référence

  python make_id_table.py > ../data/id_table.dat # crée la table d'association des
                                                 # identifiants de séquence avec
                                                 # le nom des clones

  Rscript variant_analysis.R                     # analyses et graphiques 
#+END_SRC

